{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><b>KOTAK SALESIAN SCHOOL</b></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"><b>STUDENTS DATABASE MANAGEMENT</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from sqlalchemy import create_engine, text\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Backup Files Before running New**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Backup successful: D:/postgres_backups\\backup_kotakschooldb_2025-07-30_18-25-52.sql\n"
     ]
    }
   ],
   "source": [
    "# * PostgreSQL Credentials\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"Hari@123\"\n",
    "DB_NAME = \"kotakschooldb\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "BACKUP_DIR = \"D:/postgres_backups\"  # * Backup directory\n",
    "\n",
    "# * Full path to pg_dump (if needed)\n",
    "PG_DUMP_PATH = r\"C:\\Program Files\\PostgreSQL\\17\\bin\\pg_dump.exe\"\n",
    "\n",
    "# * Ensure the backup directory exists\n",
    "os.makedirs(BACKUP_DIR, exist_ok=True)\n",
    "\n",
    "# * Generate a timestamp for the backup file\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "backup_file = os.path.join(BACKUP_DIR, f\"backup_{DB_NAME}_{timestamp}.sql\")\n",
    "\n",
    "# * Run pg_dump\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [\n",
    "            PG_DUMP_PATH,  # Use full path if not in PATH\n",
    "            \"-U\", DB_USER,\n",
    "            \"-h\", DB_HOST,\n",
    "            \"-p\", DB_PORT,\n",
    "            \"-F\", \"c\",\n",
    "            \"-b\",\n",
    "            \"-v\",\n",
    "            \"-f\", backup_file,\n",
    "            DB_NAME\n",
    "        ],\n",
    "        env={**os.environ, \"PGPASSWORD\": DB_PASSWORD},\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True,\n",
    "    )\n",
    "\n",
    "    # * Check for errors\n",
    "    if result.returncode == 0:\n",
    "        print(f\"‚úÖ Backup successful: {backup_file}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Backup failed!\\nError: {result.stderr}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ö†Ô∏è pg_dump not found at {PG_DUMP_PATH}. Check PostgreSQL installation or system PATH.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Libraries & Define Credentials**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG ===\n",
    "GOOGLE_JSON_PATHS = {\n",
    "    \"2024-25\": r\"D:\\GITHUB\\kotak-school-dbms\\google_api_keys\\woven-solution-446513-f2-2024-25.json\",\n",
    "    \"2025-26\": r\"D:\\GITHUB\\kotak-school-dbms\\google_api_keys\\woven-solution-446513-f2-2025-26.json\",\n",
    "}\n",
    "\n",
    "GOOGLE_SHEET_TITLES = {\n",
    "    \"2024-25\": \"STUDENTS DETAILS 2024-25\",\n",
    "    \"2025-26\": \"STUDENTS DETAILS 2025-26\",\n",
    "}\n",
    "\n",
    "UNIQUE_KEY = \"Adm No.\"\n",
    "\n",
    "POSTGRES_CREDENTIALS = {\n",
    "    \"username\": \"postgres\",\n",
    "    \"password\": \"Hari@123\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"kotakschooldb\",\n",
    "}\n",
    "\n",
    "TABLE_NAME1 = \"students\"\n",
    "TABLE_NAME2 = \"student_list\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Extract Data from Google Sheet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FETCH GOOGLE SHEET ===\n",
    "def fetch_data(sheet_title, worksheet_name=\"Overall\", json_path=None):\n",
    "    scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"]\n",
    "    creds = ServiceAccountCredentials.from_json_keyfile_name(json_path, scope)\n",
    "    client = gspread.authorize(creds)\n",
    "    spreadsheet = client.open(sheet_title)\n",
    "    sheet = spreadsheet.worksheet(worksheet_name)\n",
    "    data = sheet.get_all_records(head=3)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# === CLEAN COLUMN NAMES ===\n",
    "def clean_column_names(df):\n",
    "    df.columns = df.columns.str.strip()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MERGE AND TAG STATUS ===\n",
    "def merge_and_tag():\n",
    "    df_2024 = clean_column_names(fetch_data(GOOGLE_SHEET_TITLES[\"2024-25\"], \"Overall\", GOOGLE_JSON_PATHS[\"2024-25\"]))\n",
    "    df_2025 = clean_column_names(fetch_data(GOOGLE_SHEET_TITLES[\"2025-26\"], \"Overall\", GOOGLE_JSON_PATHS[\"2025-26\"]))\n",
    "\n",
    "    df_2024[\"academic_year\"] = \"2024-25\"\n",
    "    df_2025[\"academic_year\"] = \"2025-26\"\n",
    "\n",
    "    codes_2024 = set(df_2024[UNIQUE_KEY])\n",
    "    codes_2025 = set(df_2025[UNIQUE_KEY])\n",
    "\n",
    "    continuing = codes_2024.intersection(codes_2025)\n",
    "    left = codes_2024 - codes_2025\n",
    "    new = codes_2025 - codes_2024\n",
    "\n",
    "    df_2024[\"status\"] = df_2024[UNIQUE_KEY].apply(lambda x: \"left\" if x in left else \"continuing\")\n",
    "    df_2025[\"status\"] = df_2025[UNIQUE_KEY].apply(lambda x: \"new\" if x in new else \"continuing\")\n",
    "\n",
    "    return pd.concat([df_2024, df_2025], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # ‚ú® Rename columns to match your database structure\n",
    "    df.columns = [\n",
    "        \"sno\", \"adm_no\", \"name\", \"class\", \"gender\", \"mother_name\", \"father_name\",\n",
    "        \"pen_number\", \"dob\", \"phone_no\", \"religion\", \"caste\", \"sub_caste\",\n",
    "        \"second_lang\", \"remarks\", \"class_nos\", \"joined_year\", \"grades\",\n",
    "        \"academic_year\", \"status\"\n",
    "    ]\n",
    "\n",
    "    # Lowercase and strip spaces for consistency\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "    # üóìÔ∏è Convert DOB to PostgreSQL-friendly format\n",
    "    df[\"dob\"] = pd.to_datetime(df[\"dob\"], format=\"%d-%m-%Y\", errors='coerce').dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # üî¢ Convert joined_year to integer\n",
    "    df[\"joined_year\"] = pd.to_numeric(df[\"joined_year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # üßπ Remove optional junk column\n",
    "    if \"apaar_status\" in df.columns:\n",
    "        df.drop(columns=[\"apaar_status\"], inplace=True)\n",
    "\n",
    "    # Capitalize gender and reset S.No\n",
    "    df[\"gender\"] = df[\"gender\"].str.upper()\n",
    "    df[\"sno\"] = range(1, len(df) + 1)\n",
    "\n",
    "    # üü¢ Clean text fields\n",
    "    df[\"adm_no\"] = df[\"adm_no\"].astype(str).str.strip()\n",
    "    df[\"name\"] = df[\"name\"].astype(str).str.strip()\n",
    "    df[\"academic_year\"] = df[\"academic_year\"].astype(str).str.strip()\n",
    "\n",
    "    # Sort for visual clarity\n",
    "    df = df.sort_values(by=[\"academic_year\", \"class_nos\", \"gender\", \"name\"])\n",
    "\n",
    "    # Prefer non-null mother/father names when dropping duplicates\n",
    "    df_sorted = df.sort_values(\n",
    "        by=[\"adm_no\", \"mother_name\", \"father_name\"],\n",
    "        ascending=[True, True, True],\n",
    "        na_position='last'  # Non-null values come first\n",
    "    )\n",
    "\n",
    "    student_list_df = df_sorted.drop_duplicates(subset=\"adm_no\", keep=\"first\")[\n",
    "        [\n",
    "            \"adm_no\", \"name\", \"gender\", \"mother_name\", \"father_name\",\n",
    "            \"pen_number\", \"dob\", \"phone_no\", \"religion\", \"caste\",\n",
    "            \"sub_caste\", \"second_lang\", \"remarks\"\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "\n",
    "    students_df = df[\n",
    "        [\n",
    "            \"adm_no\", \"class\", \"class_nos\", \"joined_year\",\n",
    "            \"grades\", \"academic_year\", \"status\"\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # üßæ Save CSV for auditing\n",
    "    student_list_df.to_csv(r\"D:\\GITHUB\\kotak-school-dbms\\output_data\\student_list.csv\", index=False)\n",
    "    df.to_csv(r\"D:\\GITHUB\\kotak-school-dbms\\output_data\\students_data.csv\", index=False)\n",
    "\n",
    "    print(\"‚úÖ Cleaned and split data saved.\")\n",
    "\n",
    "    return student_list_df, students_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_database(df, table_name):\n",
    "    import numpy as np\n",
    "    password = urllib.parse.quote_plus(POSTGRES_CREDENTIALS[\"password\"])\n",
    "    engine = create_engine(\n",
    "        f\"postgresql+psycopg2://{POSTGRES_CREDENTIALS['username']}:{password}\"\n",
    "        f\"@{POSTGRES_CREDENTIALS['host']}:{POSTGRES_CREDENTIALS['port']}/{POSTGRES_CREDENTIALS['database']}\",\n",
    "        echo=False\n",
    "    )\n",
    "\n",
    "    # Table creation logic\n",
    "    table_create_sql = {\n",
    "        \"students\": \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS students (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                adm_no VARCHAR,\n",
    "                class VARCHAR,\n",
    "                class_nos VARCHAR,\n",
    "                joined_year INT,\n",
    "                grades VARCHAR,\n",
    "                academic_year VARCHAR,\n",
    "                status VARCHAR\n",
    "            );\n",
    "        \"\"\",\n",
    "        \"student_list\": \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS student_list (\n",
    "                adm_no VARCHAR PRIMARY KEY,\n",
    "                name VARCHAR,\n",
    "                gender VARCHAR,\n",
    "                mother_name VARCHAR,\n",
    "                father_name VARCHAR,\n",
    "                pen_number VARCHAR,\n",
    "                dob DATE,\n",
    "                phone_no VARCHAR,\n",
    "                religion VARCHAR,\n",
    "                caste VARCHAR,\n",
    "                sub_caste VARCHAR,\n",
    "                second_lang VARCHAR,\n",
    "                remarks TEXT\n",
    "            );\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            # ‚úÖ Create table if it does not exist\n",
    "            if table_name in table_create_sql:\n",
    "                conn.execute(text(table_create_sql[table_name]))\n",
    "                print(f\"üì¶ Table '{table_name}' created if it didn't exist.\")\n",
    "\n",
    "            # üóëÔ∏è Truncate before insert\n",
    "            conn.execute(text(f\"TRUNCATE TABLE {table_name} RESTART IDENTITY CASCADE;\"))\n",
    "            print(f\"üßπ Old records deleted from '{table_name}'.\")\n",
    "\n",
    "        df = df.replace({pd.NA: None, np.nan: None})\n",
    "        print(f\"‚è≥ Inserting data into '{table_name}'...\")\n",
    "\n",
    "        df.to_sql(name=table_name, con=engine, if_exists='append', index=False, method='multi', chunksize=500)\n",
    "\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(f\"SELECT COUNT(*) FROM {table_name};\"))\n",
    "            count = result.scalar()\n",
    "            print(f\"‚úÖ Insert complete. üìä Table '{table_name}' now contains {count} records.\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error updating table '{table_name}': {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Clean Extracted Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting full student import pipeline...\n",
      "\n",
      "‚úÖ Cleaned and split data saved.\n",
      "üì¶ Table 'students' created if it didn't exist.\n",
      "üßπ Old records deleted from 'students'.\n",
      "‚è≥ Inserting data into 'students'...\n",
      "‚úÖ Insert complete. üìä Table 'students' now contains 3381 records.\n",
      "\n",
      "üì¶ Table 'student_list' created if it didn't exist.\n",
      "üßπ Old records deleted from 'student_list'.\n",
      "‚è≥ Inserting data into 'student_list'...\n",
      "‚úÖ Insert complete. üìä Table 'student_list' now contains 1939 records.\n",
      "\n",
      "üéâ All done! Both 'student_list' and 'students' tables updated successfully.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ Starting full student import pipeline...\\n\")\n",
    "\n",
    "    merged_df = merge_and_tag()\n",
    "    student_list_df, students_df = clean_data(merged_df)\n",
    "\n",
    "    # Update master (student_list) and academic (students) tables\n",
    "    update_database(students_df, \"students\")\n",
    "    update_database(student_list_df, \"student_list\")\n",
    "\n",
    "    print(\"üéâ All done! Both 'student_list' and 'students' tables updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"><b>FEE REPORTS</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Google Console Service Account: myschooldb@woven-solution-446513-f2.iam.gserviceaccount.com**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Necessary Libraries & Define Global Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG ===\n",
    "GOOGLE_JSON_PATHS = {\n",
    "    \"2024-25\": r\"D:\\GITHUB\\kotak-school-dbms\\google_api_keys\\woven-solution-446513-f2-2024-25-fees.json\",\n",
    "    \"2025-26\": r\"D:\\GITHUB\\kotak-school-dbms\\google_api_keys\\woven-solution-446513-f2-2025-26-fees.json\"\n",
    "}\n",
    "\n",
    "GOOGLE_SHEET_TITLES = {\n",
    "    \"2024-25\": \"Fee Reports 2024-25\",\n",
    "    \"2025-26\": \"Fee Reports 2025-26\",\n",
    "}\n",
    "\n",
    "POSTGRES_CREDENTIALS = {\n",
    "    \"username\": \"postgres\",\n",
    "    \"password\": \"Hari@123\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"kotakschooldb\",\n",
    "}\n",
    "\n",
    "TABLE_NAME = \"fees_table\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Function for Fetching Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FETCH GOOGLE SHEET ===\n",
    "def fetch_data(sheet_title, worksheet_name=\"Overall Sheet\", json_path=None):\n",
    "    scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"]\n",
    "    creds = ServiceAccountCredentials.from_json_keyfile_name(json_path, scope)\n",
    "    client = gspread.authorize(creds)\n",
    "    spreadsheet = client.open(sheet_title)\n",
    "    sheet = spreadsheet.worksheet(worksheet_name)\n",
    "    data = sheet.get_all_records(head=3)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# === CLEAN COLUMN NAMES ===\n",
    "def clean_column_names(df):\n",
    "    df.columns = df.columns.str.strip()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MERGE AND TAG STATUS ===\n",
    "def merge_and_tag():\n",
    "    df_2024 = clean_column_names(fetch_data(GOOGLE_SHEET_TITLES[\"2024-25\"], \"Overall Sheet\", GOOGLE_JSON_PATHS[\"2024-25\"]))\n",
    "    df_2025 = clean_column_names(fetch_data(GOOGLE_SHEET_TITLES[\"2025-26\"], \"Overall Sheet\", GOOGLE_JSON_PATHS[\"2025-26\"]))\n",
    "\n",
    "    df_2024[\"academic_year\"] = \"2024-25\"\n",
    "    df_2025[\"academic_year\"] = \"2025-26\"\n",
    "\n",
    "    return pd.concat([df_2024, df_2025], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Function for Cleaning Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df = df[:-1][:-6]\n",
    "\n",
    "    df.columns = ['SNo', 'STUDENT_NAME', 'ADM_NO', 'FB_NO', 'CLASS',\n",
    "                  'Term1', 'Term2', 'Term3', 'Term4', 'Total_Fee_Paid',\n",
    "                  'Discount_Concession', 'Total_Fee_Due', 'PermissionUpto',\n",
    "                  'Fine', 'Payment_Status', 'ClassNo',\"AcNo\",'Concession_type', \"staff_name\", \"academic_year\"]\n",
    "    \n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "    # üö´ Remove blank admission numbers\n",
    "    df = df[df[\"adm_no\"].astype(str).str.strip() != \"\"]\n",
    "    df = df.dropna(subset=[\"adm_no\"])\n",
    "    # üö´ Remove blank admission numbers\n",
    "    df = df[df[\"student_name\"].astype(str).str.strip() != \"\"]\n",
    "    df = df.dropna(subset=[\"student_name\"])\n",
    "\n",
    "    columns_to_convert = [\"term1\", \"term2\", \"term3\", \"term4\", \"total_fee_paid\",\n",
    "                          \"discount_concession\", \"total_fee_due\", \"fine\"]\n",
    "    \n",
    "    df[columns_to_convert] = df[columns_to_convert].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "    df = df.drop(columns=[\"acno\", 'concession_type'])\n",
    "\n",
    "    df[\"sno\"] = range(1, len(df) + 1)\n",
    "\n",
    "    df = df.sort_values(by=[\"sno\"])\n",
    "\n",
    "    df[\"total_fees\"] = df[\"total_fee_paid\"] + df[\"discount_concession\"] + df[\"total_fee_due\"]\n",
    "\n",
    "    df = df.sort_values(by=[\"academic_year\", \"classno\", \"student_name\"], ascending=[True, True, True])\n",
    "    \n",
    "    df.to_csv(r\"D:\\GITHUB\\kotak-school-dbms\\output_data\\fees_report.csv\", index=False)\n",
    "    \n",
    "    PaymentStatus = df[[\"payment_status\"]].drop_duplicates().reset_index(drop=True)\n",
    "    PaymentStatus[\"payment_status_id\"] = range(1, len(PaymentStatus) + 1)\n",
    "    PaymentStatus = PaymentStatus[[\"payment_status_id\", \"payment_status\"]]\n",
    "    PaymentStatus.to_csv(r\"D:\\GITHUB\\kotak-school-dbms\\output_data\\payment_status_table.csv\", index=False)\n",
    "    print(\"‚úÖ Payment Status Table created successfully.\\n\")\n",
    "    \n",
    "    df = pd.merge(df, PaymentStatus, on=\"payment_status\", how=\"left\")\n",
    "    \n",
    "    df.drop(columns=[\"permissionupto\",\"payment_status\"], inplace=True)\n",
    "    \n",
    "    df.columns = df.columns.str.lower().str.strip()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Function for Updating the Database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL Connection Credentials\n",
    "POSTGRES_CREDENTIALS = {\n",
    "    \"username\": \"postgres\",\n",
    "    \"password\": \"Hari@123\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"kotakschooldb\",\n",
    "}\n",
    "\n",
    "# Encode password for URL safety\n",
    "password = urllib.parse.quote(POSTGRES_CREDENTIALS[\"password\"])\n",
    "\n",
    "# Create Engine\n",
    "engine = create_engine(f\"postgresql+psycopg2://{POSTGRES_CREDENTIALS['username']}:{password}\"\n",
    "                       f\"@{POSTGRES_CREDENTIALS['host']}:{POSTGRES_CREDENTIALS['port']}/{POSTGRES_CREDENTIALS['database']}\")\n",
    "\n",
    "def table_exists(table_name):\n",
    "    \"\"\"Check if table exists in PostgreSQL database\"\"\"\n",
    "    check_query = f\"\"\"\n",
    "    SELECT EXISTS (\n",
    "        SELECT FROM information_schema.tables \n",
    "        WHERE table_name = '{table_name}'\n",
    "    );\n",
    "    \"\"\"\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(check_query)).scalar()\n",
    "    return result\n",
    "\n",
    "def create_table():\n",
    "    \"\"\"Create table only if it does not exist\"\"\"\n",
    "    table_name = \"fees_table\"\n",
    "    \n",
    "    if table_exists(table_name):\n",
    "        print(f\"‚úÖ Table '{table_name}' already exists.\")\n",
    "        return\n",
    "\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE fees_table (\n",
    "    sno SERIAL PRIMARY KEY,\n",
    "    student_name TEXT NOT NULL,\n",
    "    adm_no TEXT,\n",
    "    fb_no TEXT,\n",
    "    class TEXT,\n",
    "    term1 NUMERIC DEFAULT 0,\n",
    "    term2 NUMERIC DEFAULT 0,\n",
    "    term3 NUMERIC DEFAULT 0,\n",
    "    term4 NUMERIC DEFAULT 0,\n",
    "    total_fee_paid NUMERIC DEFAULT 0,\n",
    "    discount_concession NUMERIC DEFAULT 0,\n",
    "    total_fee_due NUMERIC DEFAULT 0,\n",
    "    fine NUMERIC DEFAULT 0,\n",
    "    classno TEXT,\n",
    "    staff_name TEXT,\n",
    "    academic_year TEXT NOT NULL,\n",
    "    total_fees INTEGER DEFAULT 0,\n",
    "    payment_status_id INTEGER\n",
    ");\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(text(create_table_query))\n",
    "            print(f\"‚úÖ Table '{table_name}' created successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating table: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "def update_database(df):\n",
    "    password = urllib.parse.quote(POSTGRES_CREDENTIALS[\"password\"])\n",
    "    engine = create_engine(\n",
    "        f\"postgresql+psycopg2://{POSTGRES_CREDENTIALS['username']}:{password}\"\n",
    "        f\"@{POSTGRES_CREDENTIALS['host']}:{POSTGRES_CREDENTIALS['port']}/{POSTGRES_CREDENTIALS['database']}\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            # ‚úÖ Truncate existing table and reset serial ID\n",
    "            conn.execute(text(f\"TRUNCATE TABLE {TABLE_NAME} RESTART IDENTITY CASCADE;\"))\n",
    "            print(f\"‚úÖ All records from the '{TABLE_NAME}' table have been deleted.\\n\")\n",
    "\n",
    "            # ‚úÖ Add UNIQUE constraint on 'admissionno' (if it doesn't exist)\n",
    "            conn.execute(text(f\"\"\"\n",
    "                DO $$ \n",
    "                BEGIN \n",
    "                    -- Drop old constraint if exists\n",
    "                    IF EXISTS (\n",
    "                        SELECT 1 FROM information_schema.table_constraints \n",
    "                        WHERE table_name = '{TABLE_NAME}' AND constraint_name = 'unique_admissionno'\n",
    "                    ) THEN\n",
    "                        ALTER TABLE {TABLE_NAME} DROP CONSTRAINT unique_admissionno;\n",
    "                    END IF;\n",
    "\n",
    "                    -- Add new composite unique constraint if not exists\n",
    "                    IF NOT EXISTS (\n",
    "                        SELECT 1 FROM information_schema.table_constraints \n",
    "                        WHERE table_name = '{TABLE_NAME}' AND constraint_name = 'unique_adm_year'\n",
    "                    ) THEN\n",
    "                        ALTER TABLE {TABLE_NAME} ADD CONSTRAINT unique_adm_year UNIQUE (\"adm_no\", \"academic_year\");\n",
    "                    END IF;\n",
    "                END $$;\n",
    "            \"\"\"))\n",
    "\n",
    "            print(f\"‚úÖ Unique constraint on 'admissionno' ensured in the '{TABLE_NAME}' table.\\n\")\n",
    "\n",
    "        print(\"‚úÖ Table cleared. Proceeding with data insertion...\\n\")\n",
    "\n",
    "        # ‚úÖ Normalize column names\n",
    "        df.columns = df.columns.str.lower()\n",
    "\n",
    "        # ‚úÖ Drop generated or unneeded columns\n",
    "        if \"totalfees\" in df.columns:\n",
    "            df = df.drop(columns=[\"totalfees\"])\n",
    "            print(\"‚úÖ 'totalfees' column removed before insertion (generated column).\\n\")\n",
    "\n",
    "        # ‚úÖ Insert data in chunks\n",
    "        df.to_sql(\n",
    "            name=TABLE_NAME,\n",
    "            con=engine,\n",
    "            if_exists='append',\n",
    "            index=False,\n",
    "            method='multi',\n",
    "            chunksize=1000\n",
    "        )\n",
    "\n",
    "        print(f\"‚úÖ {len(df)} records successfully inserted into '{TABLE_NAME}'.\\n\")\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"‚ùå An error occurred during database update: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Main Execution Block**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Raw data merged from both years.\n",
      "\n",
      "‚úÖ Payment Status Table created successfully.\n",
      "\n",
      "‚úÖ Data cleaned and transformed successfully.\n",
      "\n",
      "‚úÖ Final columns are:\n",
      " ['sno', 'student_name', 'adm_no', 'fb_no', 'class', 'term1', 'term2', 'term3', 'term4', 'total_fee_paid', 'discount_concession', 'total_fee_due', 'fine', 'classno', 'staff_name', 'academic_year', 'total_fees', 'payment_status_id']\n",
      "‚úÖ Table 'fees_table' already exists.\n",
      "\n",
      "‚úÖ Table check/creation complete.\n",
      "\n",
      "‚úÖ Deduplicated. Final records to upload: 3381\n",
      "\n",
      "‚úÖ All records from the 'fees_table' table have been deleted.\n",
      "\n",
      "‚úÖ Unique constraint on 'admissionno' ensured in the 'fees_table' table.\n",
      "\n",
      "‚úÖ Table cleared. Proceeding with data insertion...\n",
      "\n",
      "‚úÖ 3381 records successfully inserted into 'fees_table'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # * Merge and tag both years\n",
    "    combined_df = merge_and_tag()\n",
    "    print(\"‚úÖ Raw data merged from both years.\\n\")\n",
    "\n",
    "    # * Clean and process the merged data\n",
    "    cleaned_df = clean_data(combined_df)\n",
    "    print(\"‚úÖ Data cleaned and transformed successfully.\\n\")\n",
    "    print(\"‚úÖ Final columns are:\\n\", cleaned_df.columns.to_list())\n",
    "\n",
    "    # * Create table if it does not exist\n",
    "    create_table()\n",
    "    print(\"\\n‚úÖ Table check/creation complete.\\n\")\n",
    "\n",
    "    # * Drop duplicates by adm_no + year before insert\n",
    "    cleaned_df = cleaned_df.drop_duplicates(subset=[\"adm_no\", \"academic_year\"])\n",
    "    print(f\"‚úÖ Deduplicated. Final records to upload: {len(cleaned_df)}\\n\")\n",
    "\n",
    "    # * Upload data using safe insertion\n",
    "    update_database(cleaned_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"><b>DAY WISE REPORTS</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Define Login Credentials and MySQL Credentials**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * üîπ Login Credentials\n",
    "login_url = \"https://app.myskoolcom.tech/kotak_vizag/login\"\n",
    "urls_with_years = [\n",
    "    (\"https://app.myskoolcom.tech/kotak_vizag/office_fee/fee_reports_day_wise_receipt_wise_print?academic_years_id=1\", \"2024-25\"),\n",
    "    (\"https://app.myskoolcom.tech/kotak_vizag/office_fee/fee_reports_day_wise_receipt_wise_print?academic_years_id=7\", \"2025-26\"),\n",
    "]\n",
    "\n",
    "credentials = {\n",
    "    \"uname\": \"harikiran\",\n",
    "    \"psw\": \"812551\"\n",
    "}\n",
    "\n",
    "POSTGRES_CREDENTIALS = {\n",
    "    \"username\": \"postgres\",\n",
    "    \"password\": \"Hari@123\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"kotakschooldb\",\n",
    "}\n",
    "\n",
    "TABLE_NAME = \"daywise_fees_collection\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Define Functions for Each Step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login_to_website():\n",
    "    session = requests.Session()\n",
    "    login_response = session.post(login_url, data=credentials)\n",
    "\n",
    "    if \"Invalid\" in login_response.text:\n",
    "        print(\"‚ùå Login failed! Check credentials.\\n\")\n",
    "        return None\n",
    "    else:\n",
    "        print(\"‚úÖ Login successful!\\n\")\n",
    "        return session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Function to Fetch Fee Report Page**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_fee_report_page(session, data_url):\n",
    "    response = session.get(data_url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    table = soup.find(\"table\")\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Function to Extract Data from Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_table(table):\n",
    "    rows = []\n",
    "    for tr in table.find_all(\"tr\"):\n",
    "        cols = [td.text.strip() for td in tr.find_all(\"td\")]\n",
    "        if cols:\n",
    "            rows.append(cols)\n",
    "\n",
    "    if not rows:\n",
    "        raise ValueError(\"No rows found in table\")\n",
    "\n",
    "    num_cols = len(rows[0])\n",
    "\n",
    "    if num_cols == 12:\n",
    "        header_row = [\n",
    "            \"SNo\", \"RecieptNo\", \"Class\", \"AdmissionNo\", \"StudentName\", \n",
    "            \"Date\", \"-\", \"Abacus / Vediic Maths\", \"TERM FEE\", \"TERM FEE2\", \n",
    "            \"ReceivedAmount\", \"Remarks\"\n",
    "        ]\n",
    "    elif num_cols == 11:\n",
    "        header_row = [\n",
    "            \"SNo\", \"RecieptNo\", \"Class\", \"AdmissionNo\", \"StudentName\", \n",
    "            \"Date\", \"-\", \"Abacus / Vediic Maths\", \"TERM FEE\", \n",
    "            \"ReceivedAmount\", \"Remarks\"\n",
    "        ]\n",
    "    else:\n",
    "        raise ValueError(f\"‚ö†Ô∏è Unexpected number of columns: {num_cols}\")\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=header_row)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Function to Clean Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_tag_data(df, academic_year):\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y', errors='coerce')\n",
    "    df['AdmissionNo'] = df['AdmissionNo'].astype(str)\n",
    "    df[\"Class\"] = df[\"Class\"].str.replace(\"/\", \" - \")\n",
    "    df[\"ReceivedAmount\"] = pd.to_numeric(df[\"ReceivedAmount\"], errors=\"coerce\")\n",
    "    df[\"academic_year\"] = academic_year  # Add academic year tag\n",
    "\n",
    "    # Apply \"TERM\" row slicing only for 2024-25\n",
    "    if academic_year == \"2024-25\":\n",
    "        term_index = df[df[\"SNo\"].str.contains(\"TERM\", na=False)].index\n",
    "        if not term_index.empty:\n",
    "            df = df.iloc[:term_index[0]]\n",
    "\n",
    "    # Safely drop any of these columns only if they exist\n",
    "    cols_to_drop = [\"-\", \"Abacus / Vediic Maths\", \"TERM FEE\", \"TERM FEE2\"]\n",
    "\n",
    "    df = df.drop(columns=[col for col in cols_to_drop if col in df.columns], errors=\"ignore\")\n",
    "\n",
    "    df = df.dropna(subset=[\"Date\" ])\n",
    "\n",
    "    df\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Function to Update Database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_database(df):\n",
    "    password = urllib.parse.quote(POSTGRES_CREDENTIALS[\"password\"])\n",
    "    engine = create_engine(\n",
    "        f\"postgresql+psycopg2://{POSTGRES_CREDENTIALS['username']}:{password}\"\n",
    "        f\"@{POSTGRES_CREDENTIALS['host']}:{POSTGRES_CREDENTIALS['port']}/{POSTGRES_CREDENTIALS['database']}\"\n",
    "    )\n",
    "\n",
    "    # Define SQL table creation (only if not exists)\n",
    "    create_table_sql = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {TABLE_NAME} (\n",
    "        \"SNo\" TEXT,\n",
    "        \"RecieptNo\" TEXT,\n",
    "        \"Class\" TEXT,\n",
    "        \"AdmissionNo\" TEXT,\n",
    "        \"StudentName\" TEXT,\n",
    "        \"Date\" DATE,\n",
    "        \"ReceivedAmount\" NUMERIC,\n",
    "        \"Remarks\" TEXT,\n",
    "        \"academic_year\" TEXT\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(text(create_table_sql))  # ‚úÖ Ensure table exists\n",
    "\n",
    "            conn.execute(text(\"BEGIN;\"))\n",
    "            conn.execute(text(f\"TRUNCATE TABLE {TABLE_NAME};\"))\n",
    "            conn.execute(text(\"COMMIT;\"))\n",
    "            print(f\"‚úÖ Table '{TABLE_NAME}' ensured and truncated.\\n\")\n",
    "\n",
    "            # ‚úÖ Insert DataFrame\n",
    "            df.to_sql(name=TABLE_NAME, con=engine, if_exists='append', index=False, method=\"multi\", chunksize=1000)\n",
    "            print(f\"‚úÖ {len(df)} records inserted into '{TABLE_NAME}' successfully.\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error inserting data: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    session = login_to_website()\n",
    "    if session is None:\n",
    "        return\n",
    "\n",
    "    all_dfs = []\n",
    "\n",
    "    for url, year in urls_with_years:\n",
    "        print(f\"üìÑ Fetching data for academic year: {year}\")\n",
    "        table = fetch_fee_report_page(session, url)\n",
    "\n",
    "        if table:\n",
    "            df = extract_data_from_table(table)\n",
    "            print(df.info())\n",
    "            \n",
    "            df = clean_and_tag_data(df, year)\n",
    "            print(f\"‚úÖ Data extracted for year {year} with {len(df)} records.\\n\")\n",
    "\n",
    "                        \n",
    "            print(df.info())\n",
    "            print(df.head())\n",
    "            df.to_csv(fr\"D:\\GITHUB\\kotak-school-dbms\\output_data\\fee_collection_{year}.csv\", index=False)\n",
    "            all_dfs.append(df)\n",
    "        else:\n",
    "            print(f\"‚ùå Table not found for year {year}!\")\n",
    "\n",
    "    if all_dfs:\n",
    "        final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "        final_df.to_csv(r\"D:\\GITHUB\\kotak-school-dbms\\output_data\\merged_fee_collection.csv\", index=False)\n",
    "        print(\"‚úÖ Data saved to merged_fee_collection.csv\\n\")\n",
    "\n",
    "        update_database(final_df)\n",
    "        print(\"‚úÖ Columns:\\n\", final_df.columns)\n",
    "        print(f\"‚úÖ Total {len(final_df)} records entered into database.\")\n",
    "    else:\n",
    "        print(\"‚ùå No data to process!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Run the Main Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Login successful!\n",
      "\n",
      "üìÑ Fetching data for academic year: 2024-25\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6620 entries, 0 to 6619\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   SNo                    6620 non-null   object\n",
      " 1   RecieptNo              6620 non-null   object\n",
      " 2   Class                  6616 non-null   object\n",
      " 3   AdmissionNo            6616 non-null   object\n",
      " 4   StudentName            6616 non-null   object\n",
      " 5   Date                   6616 non-null   object\n",
      " 6   -                      6616 non-null   object\n",
      " 7   Abacus / Vediic Maths  6360 non-null   object\n",
      " 8   TERM FEE               6360 non-null   object\n",
      " 9   TERM FEE2              6360 non-null   object\n",
      " 10  ReceivedAmount         5818 non-null   object\n",
      " 11  Remarks                5818 non-null   object\n",
      "dtypes: object(12)\n",
      "memory usage: 620.8+ KB\n",
      "None\n",
      "‚úÖ Data extracted for year 2024-25 with 5818 records.\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5818 entries, 0 to 5817\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   SNo             5818 non-null   object        \n",
      " 1   RecieptNo       5818 non-null   object        \n",
      " 2   Class           5818 non-null   object        \n",
      " 3   AdmissionNo     5818 non-null   object        \n",
      " 4   StudentName     5818 non-null   object        \n",
      " 5   Date            5818 non-null   datetime64[ns]\n",
      " 6   ReceivedAmount  5818 non-null   float64       \n",
      " 7   Remarks         5818 non-null   object        \n",
      " 8   academic_year   5818 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(7)\n",
      "memory usage: 409.2+ KB\n",
      "None\n",
      "  SNo RecieptNo   Class AdmissionNo                    StudentName       Date  \\\n",
      "0   1     00001  II - D       16335                    SHAIK SALMA 2024-07-15   \n",
      "1   2     00002  II - A       16365           SHEIK VISHITA KAUSAR 2024-07-15   \n",
      "2   3     00003  II - C       16516                PITTA DHASWANTH 2024-06-15   \n",
      "3   4     00004  II - B       16534  JAKKAMSETTY GNAN ANTONY CHRIS 2024-07-12   \n",
      "4   5     00005  II - A       16547                  ALIYA AASMEEN 2024-06-29   \n",
      "\n",
      "   ReceivedAmount Remarks academic_year  \n",
      "0          7150.0               2024-25  \n",
      "1          7150.0               2024-25  \n",
      "2          7150.0               2024-25  \n",
      "3          7150.0               2024-25  \n",
      "4          7150.0               2024-25  \n",
      "üìÑ Fetching data for academic year: 2025-26\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1001 entries, 0 to 1000\n",
      "Data columns (total 11 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   SNo                    1001 non-null   object\n",
      " 1   RecieptNo              1001 non-null   object\n",
      " 2   Class                  999 non-null    object\n",
      " 3   AdmissionNo            999 non-null    object\n",
      " 4   StudentName            999 non-null    object\n",
      " 5   Date                   999 non-null    object\n",
      " 6   -                      999 non-null    object\n",
      " 7   Abacus / Vediic Maths  995 non-null    object\n",
      " 8   TERM FEE               995 non-null    object\n",
      " 9   ReceivedAmount         995 non-null    object\n",
      " 10  Remarks                995 non-null    object\n",
      "dtypes: object(11)\n",
      "memory usage: 86.2+ KB\n",
      "None\n",
      "‚úÖ Data extracted for year 2025-26 with 995 records.\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 995 entries, 0 to 994\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   SNo             995 non-null    object        \n",
      " 1   RecieptNo       995 non-null    object        \n",
      " 2   Class           995 non-null    object        \n",
      " 3   AdmissionNo     995 non-null    object        \n",
      " 4   StudentName     995 non-null    object        \n",
      " 5   Date            995 non-null    datetime64[ns]\n",
      " 6   ReceivedAmount  995 non-null    float64       \n",
      " 7   Remarks         995 non-null    object        \n",
      " 8   academic_year   995 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(7)\n",
      "memory usage: 77.7+ KB\n",
      "None\n",
      "  SNo RecieptNo   Class AdmissionNo             StudentName       Date  \\\n",
      "0   1     06659  IV - B       16795  MOHAMMAD ALINA SAMDANI 2025-06-05   \n",
      "1   2     06660   V - B       16070  DONGA YASMITH JAYA SAI 2025-06-09   \n",
      "2   3     06661   V - D       15746    NAKKA YASHA YASHMINA 2025-06-11   \n",
      "3   4     06662   I - A       17109        BURLA KARTHIKEYA 2025-06-12   \n",
      "4   5     06663  II - A       16324      CHINMAYI CHANDRANA 2025-06-12   \n",
      "\n",
      "   ReceivedAmount Remarks academic_year  \n",
      "0         16600.0               2025-26  \n",
      "1         33400.0               2025-26  \n",
      "2         17200.0               2025-26  \n",
      "3         23750.0               2025-26  \n",
      "4         16000.0               2025-26  \n",
      "‚úÖ Data saved to merged_fee_collection.csv\n",
      "\n",
      "‚úÖ Table 'daywise_fees_collection' ensured and truncated.\n",
      "\n",
      "‚úÖ 6813 records inserted into 'daywise_fees_collection' successfully.\n",
      "\n",
      "‚úÖ Columns:\n",
      " Index(['SNo', 'RecieptNo', 'Class', 'AdmissionNo', 'StudentName', 'Date',\n",
      "       'ReceivedAmount', 'Remarks', 'academic_year'],\n",
      "      dtype='object')\n",
      "‚úÖ Total 6813 records entered into database.\n"
     ]
    }
   ],
   "source": [
    "# * Run the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"><b>ATTENDANCE REPORT</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import time\n",
    "# import pandas as pd\n",
    "# from datetime import datetime, timedelta\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Login to Website**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ‚úÖ Config\n",
    "# login_url = \"https://app.myskoolcom.tech/kotak_vizag/login\"\n",
    "# attendance_url = \"https://app.myskoolcom.tech/kotak_vizag/admin/attedance_grid\"\n",
    "\n",
    "# credentials = {\n",
    "#     \"uname\": \"harikiran\",\n",
    "#     \"psw\": \"812551\"\n",
    "# }\n",
    "\n",
    "# download_folder = r\"D:\\GITHUB\\kotak-school-dbms\\source_data\\Attendance Reports\"\n",
    "# merged_output_path = os.path.join(download_folder, \"MergedAttendance_2025_26.csv\")\n",
    "\n",
    "# academic_ranges = {\n",
    "#     \"2025-26\": (\"2025-06-16\", datetime.today().strftime(\"%Y-%m-%d\"))\n",
    "#     # \"2025-26\": (\"2025-06-16\", datetime.today().strftime(\"%Y-%m-%d\"))\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ‚úÖ Setup Chrome Driver\n",
    "# chrome_options = webdriver.ChromeOptions()\n",
    "# prefs = {\"download.default_directory\": download_folder}\n",
    "# chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "# driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "# wait = WebDriverWait(driver, 10)\n",
    "\n",
    "# # ‚úÖ Functions\n",
    "# def login():\n",
    "#     driver.get(login_url)\n",
    "#     wait.until(EC.presence_of_element_located((By.NAME, \"uname\"))).send_keys(credentials[\"uname\"])\n",
    "#     driver.find_element(By.NAME, \"psw\").send_keys(credentials[\"psw\"])\n",
    "#     driver.find_element(By.NAME, \"psw\").send_keys(Keys.RETURN)\n",
    "#     print(\"‚úÖ Logged in successfully!\")\n",
    "#     time.sleep(5)\n",
    "\n",
    "# def set_date_range(start, end):\n",
    "#     driver.get(attendance_url)\n",
    "#     time.sleep(2)\n",
    "#     from_date_input = wait.until(EC.presence_of_element_located((By.ID, \"from_attendance_date\")))\n",
    "#     driver.execute_script(\"arguments[0].removeAttribute('readonly')\", from_date_input)\n",
    "#     from_date_input.clear()\n",
    "#     from_date_input.send_keys(start)\n",
    "\n",
    "#     to_date_input = wait.until(EC.presence_of_element_located((By.ID, \"to_attendance_date\")))\n",
    "#     driver.execute_script(\"arguments[0].removeAttribute('readonly')\", to_date_input)\n",
    "#     to_date_input.clear()\n",
    "#     to_date_input.send_keys(end)\n",
    "\n",
    "#     print(f\"‚úÖ Date range set: {start} to {end}\")\n",
    "\n",
    "# def download_csv(filename):\n",
    "#     try:\n",
    "#         if os.path.exists(filename):\n",
    "#             os.remove(filename)\n",
    "#         download_button = wait.until(EC.element_to_be_clickable((By.ID, \"smaplecsv\")))\n",
    "#         download_button.click()\n",
    "#         time.sleep(8)\n",
    "#         downloaded = sorted(\n",
    "#             [f for f in os.listdir(download_folder) if f.endswith(\".csv\")],\n",
    "#             key=lambda x: os.path.getctime(os.path.join(download_folder, x)),\n",
    "#             reverse=True\n",
    "#         )[0]\n",
    "#         os.rename(os.path.join(download_folder, downloaded), filename)\n",
    "#         print(f\"‚úÖ Downloaded and renamed to: {filename}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Error downloading file: {e}\")\n",
    "\n",
    "# def date_batches(start, end, months=1):\n",
    "#     start_date = datetime.strptime(start, \"%Y-%m-%d\")\n",
    "#     end_date = datetime.strptime(end, \"%Y-%m-%d\")\n",
    "#     while start_date < end_date:\n",
    "#         batch_end = min(start_date + timedelta(days=30 * months), end_date)\n",
    "#         yield (start_date.strftime(\"%Y-%m-%d\"), batch_end.strftime(\"%Y-%m-%d\"))\n",
    "#         start_date = batch_end + timedelta(days=1)\n",
    "\n",
    "# def merge_csvs(folder, output_file, year_filter=\"2025-26\"):\n",
    "#     all_csvs = [\n",
    "#         os.path.join(folder, f)\n",
    "#         for f in os.listdir(folder)\n",
    "#         if f.endswith(\".csv\") and year_filter in f\n",
    "#     ]\n",
    "\n",
    "#     merged_df = pd.DataFrame()\n",
    "\n",
    "#     for f in all_csvs:\n",
    "#         try:\n",
    "#             df = pd.read_csv(f, low_memory=False)\n",
    "#             if \"Students Number\" in df.columns:\n",
    "#                 # Merge logic: remove duplicates by date + student number\n",
    "#                 df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "#                 df = df.dropna(subset=[\"Date\", \"Students Number\"])\n",
    "\n",
    "#                 # Merge with deduplication\n",
    "#                 if not merged_df.empty:\n",
    "#                     merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "#                     merged_df.drop_duplicates(subset=[\"Date\", \"Students Number\"], keep=\"last\", inplace=True)\n",
    "#                 else:\n",
    "#                     merged_df = df\n",
    "#                 print(f\"üîÑ Merged file (with Students Number): {os.path.basename(f)}\")\n",
    "#             else:\n",
    "#                 # Append directly if \"Students Number\" not found\n",
    "#                 merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "#                 print(f\"‚ûï Appended file (no Students Number): {os.path.basename(f)}\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"‚ùå Error reading file {f}: {e}\")\n",
    "\n",
    "#     merged_df.to_csv(output_file, index=False)\n",
    "#     print(f\"‚úÖ Final merged file saved: {output_file}\")\n",
    "\n",
    "#     # ‚úÖ MAIN Execution\n",
    "# login()\n",
    "\n",
    "# # ‚úÖ MAIN Execution\n",
    "# login()\n",
    "\n",
    "# for year, (start, end) in academic_ranges.items():\n",
    "#     print(f\"\\nüìÖ Downloading attendance for {year}\")\n",
    "#     for i, (s, e) in enumerate(date_batches(start, end)):\n",
    "#         s_fmt = datetime.strptime(s, \"%Y-%m-%d\")\n",
    "#         e_fmt = datetime.strptime(e, \"%Y-%m-%d\")\n",
    "#         filename = f\"Attendance_{year}_{s_fmt.strftime('%b')}_{e_fmt.strftime('%b')}.csv\"\n",
    "#         filepath = os.path.join(download_folder, filename)\n",
    "#         set_date_range(s_fmt.strftime(\"%Y-%m-%d\"), e_fmt.strftime(\"%Y-%m-%d\"))\n",
    "#         download_csv(filepath)\n",
    "\n",
    "# # ‚ùå No merging now ‚Äì only individual files will be downloaded and renamed\n",
    "# # merge_csvs(download_folder, merged_output_path, year_filter=\"2025-26\")\n",
    "\n",
    "# driver.quit()\n",
    "# print(\"‚úÖ All attendance downloads complete ‚Äì individual files saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üìå Step 1: Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sqlalchemy import create_engine\n",
    "# import logging\n",
    "# import numpy as np\n",
    "# import urllib\n",
    "# import logging\n",
    "# import traceback\n",
    "# from datetime import datetime\n",
    "\n",
    "# # * Configure logging\n",
    "# logging.basicConfig(filename=r\"D:\\GITHUB\\kotak-school-dbms\\output_data\\attendance_report.log\", level=logging.ERROR, \n",
    "#                     format=\"%(asctime)s - %(levelname)s - %(message)s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üìå Step 2: Define PostgreSQl Credentials & Table Name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # * MySQL Credentials\n",
    "# POSTGRES_CREDENTIALS = {\n",
    "#     \"username\": \"postgres\",\n",
    "#     \"password\": \"Hari@123\",\n",
    "#     \"host\": \"localhost\",\n",
    "#     \"port\": \"5432\",\n",
    "#     \"database\": \"kotakschooldb\",\n",
    "# }\n",
    "# TABLE_NAME = \"attendance_report\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üìå Step 3: Load and Clean Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_and_clean_data(file1, file2, file3, file4=None, file5=None):\n",
    "#     # Load DataFrames\n",
    "#     dfs = [pd.read_csv(f) for f in [file1, file2, file3, file4, file5] if f is not None]\n",
    "\n",
    "#     # Clean column names\n",
    "#     for i in range(len(dfs)):\n",
    "#         dfs[i].columns = dfs[i].columns.str.strip().str.replace('\"', '', regex=False)\n",
    "\n",
    "#     # Ensure unique columns before merge to avoid suffix collision\n",
    "#     base_df = dfs[0]\n",
    "\n",
    "#     for df in dfs[1:]:\n",
    "#         # Remove columns from df that would cause _x/_y clashes (except 'Students Number')\n",
    "#         conflict_cols = [col for col in df.columns if col in base_df.columns and col != 'Students Number']\n",
    "#         df = df.drop(columns=conflict_cols, errors='ignore')\n",
    "\n",
    "#         # Merge safely\n",
    "#         base_df = base_df.merge(df, on=\"Students Number\", how=\"outer\")\n",
    "\n",
    "#     df = base_df\n",
    "\n",
    "#     # Merge fields like Name, Class if duplicated from earlier columns\n",
    "#     for field in ['Name', 'Class']:\n",
    "#         col_x, col_y = f\"{field}_x\", f\"{field}_y\"\n",
    "#         if col_x in df.columns and col_y in df.columns:\n",
    "#             df[field] = df[col_x].combine_first(df[col_y])\n",
    "#             df.drop([col_x, col_y], axis=1, inplace=True)\n",
    "#         elif col_x in df.columns:\n",
    "#             df[field] = df.pop(col_x)\n",
    "#         elif col_y in df.columns:\n",
    "#             df[field] = df.pop(col_y)\n",
    "\n",
    "#     # Drop any remaining _x/_y suffix columns\n",
    "#     df = df.drop(columns=[col for col in df.columns if col.endswith('_x') or col.endswith('_y')], errors='ignore')\n",
    "\n",
    "#     # Rename key identifier\n",
    "#     df = df.rename(columns={\"Students Number\": \"AdmissionNo\"})\n",
    "\n",
    "#     # Drop unnecessary columns\n",
    "#     drop_cols = ['Present Days', 'Absent Days', 'Toral Working Days']\n",
    "#     df = df.drop(columns=[col for col in drop_cols if col in df.columns], errors='ignore')\n",
    "\n",
    "#     # Reorder columns\n",
    "#     key_cols = ['AdmissionNo', 'Name', 'Class']\n",
    "#     other_cols = [col for col in df.columns if col not in key_cols]\n",
    "#     df = df[key_cols + other_cols]\n",
    "\n",
    "#     return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **üìå Step 4: Process Attendance Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# def process_attendance_data(df):\n",
    "#     # * Step 1: Clean AdmissionNo (remove 786 and purely alphabetical ones)\n",
    "#     df = df[~(df[\"AdmissionNo\"].astype(str) == \"786\") & ~df[\"AdmissionNo\"].astype(str).str.match(r\"^[a-zA-Z]+$\")].copy()\n",
    "\n",
    "#     # * Step 2: Clean Class name (remove ICSE wrapper)\n",
    "#     df[\"Class\"] = df[\"Class\"].astype(str).str.replace(r\"ICSE \\((.*?)\\)\", r\"\\1\", regex=True)\n",
    "\n",
    "#     # * Step 3: Load class info with academic year\n",
    "#     student_df = pd.read_csv(r\"D:\\GITHUB\\kotak-school-dbms\\output_data\\fees_report.csv\")[[\"adm_no\", \"academic_year\", \"class\"]]\n",
    "#     print(\"‚úÖ Students Before Merging\\n\", len(df[\"AdmissionNo\"].unique()))\n",
    "#     df = df[df[\"AdmissionNo\"].isin(student_df[\"adm_no\"])]\n",
    "#     print(\"‚úÖ Students After Merging\\n\", len(df[\"AdmissionNo\"].unique()))\n",
    "\n",
    "#     # * Step 4: Unpivot attendance columns to Date-wise rows\n",
    "#     df_unpivot = pd.melt(df, id_vars=[\"AdmissionNo\", \"Name\", \"Class\"], var_name=\"Date\", value_name=\"AttendanceStatus\")\n",
    "#     df_unpivot[\"Date\"] = pd.to_datetime(df_unpivot[\"Date\"], format='%d.%m.%Y', errors='coerce')\n",
    "\n",
    "#     # * Step 5: Remove invalid past records for new students\n",
    "#     numeric_mask = df_unpivot[\"AdmissionNo\"].str.isnumeric()\n",
    "#     df_unpivot.loc[numeric_mask, \"adm_no_int\"] = df_unpivot.loc[numeric_mask, \"AdmissionNo\"].astype(int)\n",
    "#     df_unpivot = df_unpivot[\n",
    "#         ~((df_unpivot[\"Date\"] < datetime(2024, 4, 1)) & (df_unpivot[\"adm_no_int\"] > 17165))\n",
    "#     ]\n",
    "#     df_unpivot.drop(columns=[\"adm_no_int\"], inplace=True)\n",
    "\n",
    "#     df_unpivot[\"id\"] = range(1, len(df_unpivot) + 1)\n",
    "\n",
    "#     if df_unpivot[\"Date\"].isna().sum() > 0:\n",
    "#         print(\"‚ö†Ô∏è Warning: Some Date values were invalid and converted to NaT.\")\n",
    "\n",
    "#     df_unpivot = df_unpivot.sort_values(\"Date\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "#     # * Step 6: Mark \"Not Joined\"\n",
    "#     first_attendance_dates = df_unpivot[df_unpivot['AttendanceStatus'].notna()].groupby('AdmissionNo')['Date'].min()\n",
    "#     df_unpivot['AttendanceStatus'] = df_unpivot.apply(\n",
    "#         lambda row: \"Not Joined\" if row['Date'] < first_attendance_dates.get(row['AdmissionNo'], row['Date']) else row['AttendanceStatus'],\n",
    "#         axis=1\n",
    "#     )\n",
    "\n",
    "#     # * Step 7: Prioritize and deduplicate attendance\n",
    "#     priority_map = {'P': 2, 'A': 1, 'H': 3, 'Not Joined': 4, 'TC': 5}\n",
    "#     df_unpivot['Priority'] = df_unpivot[\"AttendanceStatus\"].map(priority_map)\n",
    "#     df_unpivot = df_unpivot.sort_values(by=['AdmissionNo', 'Date', 'Priority']) \\\n",
    "#                            .drop_duplicates(subset=['AdmissionNo', 'Date'], keep='first') \\\n",
    "#                            .drop(columns=['Priority'])\n",
    "\n",
    "#     # * Step 8: Clean Class + Standardize AttendanceStatus\n",
    "#     df_unpivot['Class'] = df_unpivot['Class'].str.replace(\"Pre KG - \", \"Pre KG\")\n",
    "#     df_unpivot[\"AttendanceStatus\"] = df_unpivot[\"AttendanceStatus\"].replace({\n",
    "#         'P': \"Present\", 'A': \"Absent\", 'H': \"Holiday\"\n",
    "#     })\n",
    "#     df_unpivot.sort_values(by=['Date'], ascending=False, inplace=True)\n",
    "\n",
    "#     # * Step 9: Assign academic year from Date\n",
    "#     df_unpivot['academic_year'] = df_unpivot['Date'].apply(\n",
    "#         lambda d: \"2024-25\" if pd.Timestamp(\"2024-07-17\") <= d <= pd.Timestamp(\"2025-03-31\")\n",
    "#         else \"2025-26\" if pd.Timestamp(\"2025-06-16\") <= d <= pd.Timestamp(datetime.today().date())\n",
    "#         else \"\"\n",
    "#     )\n",
    "\n",
    "#     # * Step 10: Assign ClassNo by academic year\n",
    "#     student_df[\"adm_no\"] = student_df[\"adm_no\"].astype(str)\n",
    "#     lookup_2024 = student_df[student_df[\"academic_year\"] == \"2024-25\"]\n",
    "#     lookup_2025 = student_df[student_df[\"academic_year\"] == \"2025-26\"]\n",
    "\n",
    "#     lookup_map_2024 = {row[\"adm_no\"]: row[\"class\"] for _, row in lookup_2024.iterrows()}\n",
    "#     lookup_map_2025 = {row[\"adm_no\"]: row[\"class\"] for _, row in lookup_2025.iterrows()}\n",
    "\n",
    "#     class_mapping = {\n",
    "#         \"Pre KG\": 1, \"LKG - A\": 2, \"LKG - B\": 3, \"UKG - A\": 4, \"UKG - B\": 5, \"UKG - C\": 6,\n",
    "#         \"I - A\": 7, \"I - B\": 8, \"I - C\": 9, \"I - D\": 10,\n",
    "#         \"II - A\": 11, \"II - B\": 12, \"II - C\": 13, \"II - D\": 14,\n",
    "#         \"III - A\": 15, \"III - B\": 16, \"III - C\": 17, \"III - D\": 18,\n",
    "#         \"IV - A\": 19, \"IV - B\": 20, \"IV - C\": 21, \"IV - D\": 22,\n",
    "#         \"V - A\": 23, \"V - B\": 24, \"V - C\": 25, \"V - D\": 26,\n",
    "#         \"VI - A\": 27, \"VI - B\": 28, \"VI - C\": 29, \"VI - D\": 30,\n",
    "#         \"VII - A\": 31, \"VII - B\": 32, \"VII - C\": 33, \"VII - D\": 34,\n",
    "#         \"VIII - A\": 35, \"VIII - B\": 36, \"VIII - C\": 37, \"VIII - D\": 38,\n",
    "#         \"IX - A\": 39, \"IX - B\": 40, \"IX - C\": 41,\n",
    "#         \"X - A\": 42, \"X - B\": 43, \"X - C\": 44\n",
    "#     }\n",
    "\n",
    "#     def get_class_no_2024(adm_no):\n",
    "#         class_name = lookup_map_2024.get(str(adm_no), \"\")\n",
    "#         return class_mapping.get(class_name, np.nan)\n",
    "\n",
    "#     def get_class_no_2025(adm_no):\n",
    "#         class_name = lookup_map_2025.get(str(adm_no), \"\")\n",
    "#         return class_mapping.get(class_name, np.nan)\n",
    "\n",
    "#     df_2024 = df_unpivot[df_unpivot[\"academic_year\"] == \"2024-25\"].copy()\n",
    "#     df_2025 = df_unpivot[df_unpivot[\"academic_year\"] == \"2025-26\"].copy()\n",
    "\n",
    "#     valid_adm_nos_2025 = set(lookup_map_2025.keys())\n",
    "#     df_2025 = df_2025[df_2025[\"AdmissionNo\"].astype(str).isin(valid_adm_nos_2025)].copy()\n",
    "\n",
    "#     df_2024[\"ClassNo\"] = df_2024[\"AdmissionNo\"].apply(get_class_no_2024)\n",
    "#     df_2025[\"ClassNo\"] = df_2025[\"AdmissionNo\"].apply(get_class_no_2025)\n",
    "\n",
    "#     df_unpivot = pd.concat([df_2024, df_2025], ignore_index=True)\n",
    "#     df_unpivot[\"ClassNo\"] = df_unpivot[\"ClassNo\"].fillna(0).astype(int)\n",
    "\n",
    "#     # * Step 11: Grade level (classId)\n",
    "#     grade_mapping = [\n",
    "#         (\"Pre KG\", 1), (\"LKG\", 2), (\"UKG\", 3),\n",
    "#         (\"I\", 4), (\"II\", 5), (\"III\", 6), (\"IV\", 7), (\"V\", 8),\n",
    "#         (\"VI\", 9), (\"VII\", 10), (\"VIII\", 11), (\"IX\", 12), (\"X\", 13)\n",
    "#     ]\n",
    "#     conditions = [df_unpivot['Class'].str.contains(fr\"\\b{k}\\b\", na=False, regex=True) for k, _ in grade_mapping]\n",
    "#     choices = [v for _, v in grade_mapping]\n",
    "#     df_unpivot['classId'] = np.select(conditions, choices, default=0).astype(int)\n",
    "\n",
    "#     # * Step 12: AttendanceStatusId\n",
    "#     AttendanceStatus_mapping = [(\"Absent\", 1), (\"Present\", 2), (\"Not Joined\", 3), (\"Holiday\", 4)]\n",
    "#     conditions = [df_unpivot['AttendanceStatus'].str.contains(k, na=False) for k, _ in AttendanceStatus_mapping]\n",
    "#     choices = [v for _, v in AttendanceStatus_mapping]\n",
    "#     df_unpivot['AttendanceStatusId'] = np.select(conditions, choices, default=0).astype(int)\n",
    "\n",
    "#     # * Step 13: BranchId\n",
    "#     branch_mapping = [\n",
    "#         ('Pre KG', 1), ('LKG', 1), ('UKG', 1),\n",
    "#         ('I', 2), ('II', 2), ('III', 2), ('IV', 2), ('V', 2),\n",
    "#         ('VI', 3), ('VII', 3), ('VIII', 3), ('IX', 3), ('X', 3)\n",
    "#     ]\n",
    "#     conditions = [df_unpivot['Class'].str.contains(fr\"\\b{k}\\b\", na=False, regex=True) for k, _ in branch_mapping]\n",
    "#     choices = [v for _, v in branch_mapping]\n",
    "#     df_unpivot['branchId'] = np.select(conditions, choices, default=0).astype(int)\n",
    "\n",
    "#     # ‚úÖ Final output\n",
    "#     df_unpivot = df_unpivot[[\n",
    "#         \"id\", \"Date\", \"AdmissionNo\", \"ClassNo\", \"classId\", \"branchId\", \"AttendanceStatusId\", \"academic_year\"\n",
    "#     ]]\n",
    "#     df_unpivot.columns = [c.lower() for c in df_unpivot.columns]\n",
    "\n",
    "#     print(f\"‚úÖ Processed data with {len(df_unpivot)} rows.\")\n",
    "#     print(f\"‚úÖ Columns are:\\n {df_unpivot.columns}\")\n",
    "#     return df_unpivot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üìå Step 5: Insert Data into PostgreSQL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sqlalchemy import text\n",
    "\n",
    "# def ensure_table_exists():\n",
    "#     create_table_sql = f\"\"\"\n",
    "#     CREATE TABLE IF NOT EXISTS {TABLE_NAME} (\n",
    "#         id SERIAL PRIMARY KEY,\n",
    "#         date DATE,\n",
    "#         admissionno TEXT,\n",
    "#         classno INTEGER,\n",
    "#         classid INTEGER,\n",
    "#         branchid INTEGER,\n",
    "#         attendancestatusid INTEGER,\n",
    "#         academic_year TEXT NOT NULL\n",
    "#     );\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         with engine.begin() as connection:  # ‚úÖ ensures DDL is committed\n",
    "#             connection.execute(text(create_table_sql))\n",
    "#         print(f\"‚úÖ Table '{TABLE_NAME}' ensured.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Failed to create or check table '{TABLE_NAME}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create database engine\n",
    "# password = urllib.parse.quote(POSTGRES_CREDENTIALS[\"password\"])\n",
    "# engine = create_engine(\n",
    "#     f\"postgresql+psycopg2://{POSTGRES_CREDENTIALS['username']}:{password}\"\n",
    "#     f\"@{POSTGRES_CREDENTIALS['host']}:{POSTGRES_CREDENTIALS['port']}/{POSTGRES_CREDENTIALS['database']}\"\n",
    "# )\n",
    "\n",
    "# def update_database(df):\n",
    "#     \"\"\"Use PostgreSQL COPY for ultra-fast data insertion.\"\"\"\n",
    "#     csv_path = (r\"D:\\GITHUB\\kotak-school-dbms\\output_data\\attendance_report.csv\")\n",
    "\n",
    "#     # ‚úÖ Ensure column names are lowercase to match table definition\n",
    "#     df.columns = [c.lower() for c in df.columns]\n",
    "\n",
    "#     # ‚úÖ Save DataFrame to CSV\n",
    "#     df.to_csv(csv_path, index=False, header=False)\n",
    "\n",
    "#     try:\n",
    "#         conn = engine.raw_connection()\n",
    "#         cursor = conn.cursor()\n",
    "\n",
    "#         print(f\"üîÑ Truncating table: {TABLE_NAME}\")\n",
    "#         cursor.execute(f\"TRUNCATE TABLE {TABLE_NAME};\")\n",
    "#         conn.commit()\n",
    "\n",
    "#         with open(csv_path, \"r\") as f:\n",
    "#             cursor.copy_from(f, TABLE_NAME, sep=\",\")  # ‚úÖ lowercase and unquoted\n",
    "\n",
    "#         conn.commit()\n",
    "#         cursor.close()\n",
    "#         conn.close()\n",
    "\n",
    "#         print(f\"‚úÖ Data copied to '{TABLE_NAME}' using COPY command!\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå COPY failed: {e}\")\n",
    "#         logging.error(traceback.format_exc())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üìå Step 6: Run the Full Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     file1 = r\"D:\\GITHUB\\kotak-school-dbms\\source_data\\Attendance Reports\\AttendanceReportUptoSeptember_2024_25.csv\"\n",
    "#     file2 = r\"D:\\GITHUB\\kotak-school-dbms\\source_data\\Attendance Reports\\AttendanceOctoberToDecember_2024_25.csv\"\n",
    "#     file3 = r\"D:\\GITHUB\\kotak-school-dbms\\source_data\\Attendance Reports\\AttendanceUptoMarch_2024_25.csv\"\n",
    "#     file4 = r\"D:\\GITHUB\\kotak-school-dbms\\source_data\\Attendance Reports\\Attendance_2025-26_Jun_Jul.csv\"\n",
    "#     file5 = r\"D:\\GITHUB\\kotak-school-dbms\\source_data\\Attendance Reports\\Attendance_2025-26_Jul_Jul.csv\"\n",
    "#     output_file = r\"D:\\GITHUB\\kotak-school-dbms\\output_data\\attendance_report.csv\"\n",
    "    \n",
    "#     try:\n",
    "#         print(\"Loading and cleaning data...\\n\")\n",
    "#         df = load_and_clean_data(file1, file2, file3, file4, file5)\n",
    "#         print(f\"‚úÖ Data loaded with {df.shape[0]} rows.\\n\")\n",
    "        \n",
    "#         print(\"Processing attendance data...\\n\")\n",
    "#         df_unpivot = process_attendance_data(df)\n",
    "#         df_unpivot.to_csv(output_file, index=False)\n",
    "#         print(f\"‚úÖ Processed data with {df_unpivot.shape[0]} rows.\\n\")\n",
    "#         print(\"‚úÖ Columns are:\\n\", df_unpivot.columns)\n",
    "#         print(max(df_unpivot[\"date\"]))\n",
    "#         print((df_unpivot.head()))\n",
    "                \n",
    "#         print(\"Updating database...\\n\")\n",
    "#         ensure_table_exists()\n",
    "#         update_database(df_unpivot)\n",
    "#         print(\"‚úÖ Data updated successfully!\\n\")\n",
    "\n",
    "#         print(\"‚úÖ Attendance report processing completed successfully!\\n\")\n",
    "#         print(f\"‚úÖ No of Rows: {df_unpivot.shape[0]}\\n\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå An unexpected error occurred. Error: {e}\\n\")\n",
    "#         logging.error(f\"‚ùå Unexpected error: {e}\\n\")\n",
    "\n",
    "\n",
    "# # * Run the script\n",
    "# main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"><b>Class Table</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sqlalchemy import create_engine, text\n",
    "\n",
    "# POSTGRES_CREDENTIALS = {\n",
    "#     \"username\": \"postgres\",\n",
    "#     \"password\": \"Hari@123\",\n",
    "#     \"host\": \"localhost\",\n",
    "#     \"port\": \"5432\",\n",
    "#     \"database\": \"kotakschooldb\",\n",
    "# }\n",
    "# TABLE_NAME = \"class_table\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(r\"D:\\GITHUB\\kotak-school-dbms\\output_data\\class_section_grade_table.csv\")\n",
    "# # df[\"ClassNo\"] = df[\"ClassNo\"].astype(int)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import traceback\n",
    "# import logging\n",
    "# import pandas as pd\n",
    "# import urllib\n",
    "# import io\n",
    "# from sqlalchemy import create_engine, text\n",
    "# from sqlalchemy.exc import OperationalError\n",
    "\n",
    "# # Retry settings\n",
    "# MAX_RETRIES = 3\n",
    "# RETRY_DELAY = 5  # Seconds\n",
    "\n",
    "# def bulk_insert_postgres(df, conn, table_name):\n",
    "#     \"\"\"Fast bulk insert using PostgreSQL COPY command.\"\"\"\n",
    "#     with conn.connection.cursor() as cur:\n",
    "#         output = io.StringIO()\n",
    "#         df.to_csv(output, sep=\"\\t\", index=False, header=False)\n",
    "#         output.seek(0)\n",
    "#         cur.copy_from(output, table_name, sep=\"\\t\", null=\"NULL\")\n",
    "#         conn.connection.commit()\n",
    "\n",
    "# def update_database(df):\n",
    "#     \"\"\"Insert attendance data into PostgreSQL database with retry logic.\"\"\"\n",
    "#     password = urllib.parse.quote(POSTGRES_CREDENTIALS[\"password\"])\n",
    "#     engine = create_engine(f\"postgresql+psycopg2://{POSTGRES_CREDENTIALS['username']}:{password}\"\n",
    "#                            f\"@{POSTGRES_CREDENTIALS['host']}:{POSTGRES_CREDENTIALS['port']}/{POSTGRES_CREDENTIALS['database']}\")\n",
    "\n",
    "#     for attempt in range(1, MAX_RETRIES + 1):\n",
    "#         try:\n",
    "#             print(f\"üîÑ Attempt {attempt}: Connecting to database {POSTGRES_CREDENTIALS['database']} at {POSTGRES_CREDENTIALS['host']}...\")\n",
    "#             with engine.begin() as conn:\n",
    "#                 print(f\"‚úÖ Connection established.\")\n",
    "\n",
    "#                 # Create Table if it does not exist\n",
    "#                 print(f\"Checking if table '{TABLE_NAME}' exists...\")\n",
    "                \n",
    "#                 # Truncate the table before inserting data\n",
    "#                 print(f\"Truncating existing table: {TABLE_NAME}\")\n",
    "#                 conn.execute(text(f\"TRUNCATE TABLE {TABLE_NAME} CASCADE;\"))\n",
    "                \n",
    "#                 print(f\"Deleting data from {TABLE_NAME} table...\")\n",
    "#                 conn.execute(text(f\"DELETE FROM {TABLE_NAME};\"))\n",
    "\n",
    "\n",
    "#                 # Fast Bulk Insert\n",
    "#                 print(f\"Inserting data into {TABLE_NAME} table...\")\n",
    "#                 bulk_insert_postgres(df, conn, TABLE_NAME)\n",
    "\n",
    "#                 print(f\"‚úÖ Data successfully inserted into '{TABLE_NAME}' table.\")\n",
    "#                 return  # Exit function if successful\n",
    "\n",
    "#         except OperationalError as e:\n",
    "#             print(f\"‚ùå OperationalError: {e}\")\n",
    "#             logging.error(f\"‚ùå OperationalError: {e}\")\n",
    "#             logging.error(\"Error Traceback:\\n\" + traceback.format_exc())\n",
    "\n",
    "#             if attempt < MAX_RETRIES:\n",
    "#                 print(f\"üîÑ Retrying in {RETRY_DELAY} seconds...\")\n",
    "#                 time.sleep(RETRY_DELAY)\n",
    "#             else:\n",
    "#                 print(\"‚ùå Max retries reached. Could not update the database.\")\n",
    "#                 logging.error(\"‚ùå Max retries reached. Could not update the database.\")\n",
    "#                 return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_database(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"><b>FEE COLLECTION REPORT 2024-25</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import numpy as np\n",
    "import logging\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå Logging\n",
    "logging.basicConfig(filename=\"fee_collection_merge.log\", level=logging.ERROR)\n",
    "\n",
    "# üîê Credentials & URLs\n",
    "login_url = \"https://app.myskoolcom.tech/kotak_vizag/login\"\n",
    "credentials = {\"uname\": \"harikiran\", \"psw\": \"812551\"}\n",
    "urls = {\n",
    "    \"2024_25\": \"https://app.myskoolcom.tech/kotak_vizag/office_fee/fee_consolidate_report_print?&from=2024-04-01&academic_years_id=7&status=1&imageField=Search\",\n",
    "    \"2025_26\": \"https://app.myskoolcom.tech/kotak_vizag/office_fee/fee_consolidate_report_print?&from=2025-04-01&academic_years_id=1&status=1&imageField=Search\"\n",
    "}\n",
    "\n",
    "# üõ†Ô∏è PostgreSQL Config\n",
    "POSTGRES_CREDENTIALS = {\n",
    "    \"username\": \"postgres\",\n",
    "    \"password\": \"Hari@123\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"kotakschooldb\",\n",
    "}\n",
    "TABLE_NAME = \"fees_collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîå Create Engine\n",
    "def get_engine():\n",
    "    password = urllib.parse.quote(POSTGRES_CREDENTIALS[\"password\"])\n",
    "    return create_engine(\n",
    "        f\"postgresql+psycopg2://{POSTGRES_CREDENTIALS['username']}:{password}\"\n",
    "        f\"@{POSTGRES_CREDENTIALS['host']}:{POSTGRES_CREDENTIALS['port']}/{POSTGRES_CREDENTIALS['database']}\"\n",
    "    )\n",
    "\n",
    "# üîë Login\n",
    "def login_to_website():\n",
    "    session = requests.Session()\n",
    "    response = session.post(login_url, data=credentials)\n",
    "    if \"Invalid\" in response.text:\n",
    "        print(\"‚ùå Login failed!\")\n",
    "        return None\n",
    "    print(\"‚úÖ Login successful!\")\n",
    "    return session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßæ Convert HTML table to DataFrame\n",
    "def table_to_dataframe(table):\n",
    "    headers = [th.get_text(strip=True) for th in table.find_all(\"th\")]\n",
    "    rows = [[td.get_text(strip=True) for td in tr.find_all(\"td\")] for tr in table.find_all(\"tr\")[1:]]\n",
    "    return pd.DataFrame(rows, columns=headers) if rows else None\n",
    "\n",
    "# üì• Fetch fee table from a given URL\n",
    "def fetch_fee_table(session, url):\n",
    "    response = session.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    tables = soup.find_all(\"table\", class_=\"b-t\")\n",
    "    all_data = []\n",
    "\n",
    "    for table in tables:\n",
    "        df = table_to_dataframe(table)\n",
    "        if df is not None:\n",
    "            all_data.append(df)\n",
    "\n",
    "    return pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()\n",
    "\n",
    "\n",
    "# üßπ Clean data\n",
    "def clean_data(df, academic_year):\n",
    "    df = df[~df.iloc[:, 0].astype(str).str.startswith(\"Total\", na=False)].copy()\n",
    "    df[\"Admin No.\"] = df[\"Admin No.\"].astype(str)\n",
    "    \n",
    "    df.columns = ['SNo', 'AdmissionNo', 'Name', 'Abacus1', 'TermFee1',\n",
    "                  'Total_Fees', 'Abacus2', 'TermFee2',\n",
    "                  'Total_Fee_Paid', 'Discount_Concession', 'Total_Due']\n",
    "    \n",
    "    numeric_columns = [\"Total_Fees\", \"Total_Fee_Paid\", \"Discount_Concession\", \"Total_Due\"]\n",
    "    for col in numeric_columns:\n",
    "        df[col] = df[col].astype(str).str.replace(\",\", \"\").replace([\"\", \"None\", \"nan\", \"NaN\", np.nan], 0)\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    df = df.drop(columns=[\"SNo\", \"Abacus1\", \"Abacus2\", \"TermFee1\", \"TermFee2\"])\n",
    "    df[\"academic_year\"] = academic_year  # Add source year column\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "def ensure_fees_collection_table(engine):\n",
    "    create_table_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS fees_collection (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        admissionno TEXT,\n",
    "        name TEXT,\n",
    "        total_fees INTEGER,\n",
    "        total_fee_paid INTEGER,\n",
    "        discount_concession INTEGER,\n",
    "        total_due INTEGER,\n",
    "        academic_year TEXT\n",
    "    );\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            conn.execute(text(create_table_sql))\n",
    "        print(\"‚úÖ Table 'fees_collection' ensured.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating table: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üõ¢Ô∏è Insert into PostgreSQL\n",
    "def update_database(df, table_name):\n",
    "    engine = get_engine()\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            print(f\"‚ö†Ô∏è Deleting old records from '{table_name}'...\")\n",
    "            conn.execute(text(f\"DELETE FROM {table_name};\"))\n",
    "            print(f\"‚úÖ Table '{table_name}' cleared.\")\n",
    "        df.columns = df.columns.str.lower()\n",
    "        print(f\"üì• Inserting {len(df)} rows...\")\n",
    "        df.to_sql(name=table_name, con=engine, if_exists='append', index=False, method='multi', chunksize=1000)\n",
    "        print(f\"‚úÖ Inserted into '{table_name}' successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error inserting: {e}\")\n",
    "        logging.error(f\"Database insert error: {e}\")\n",
    "    finally:\n",
    "        engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Login successful!\n",
      "\n",
      "üîÑ Fetching data for 2024_25...\n",
      "\n",
      "üîÑ Fetching data for 2025_26...\n",
      "üìÅ Saved to merged_fee_collection.csv\n",
      "‚úÖ Table 'fees_collection' ensured.\n",
      "‚úÖ Fees collection table ensured.\n",
      "‚ö†Ô∏è Deleting old records from 'fees_collection'...\n",
      "‚úÖ Table 'fees_collection' cleared.\n",
      "üì• Inserting 3227 rows...\n",
      "‚úÖ Inserted into 'fees_collection' successfully.\n",
      "‚úÖ All done! Total records: 3227\n"
     ]
    }
   ],
   "source": [
    "# üöÄ Main Logic\n",
    "def main():\n",
    "    session = login_to_website()\n",
    "    if session is None:\n",
    "        return\n",
    "\n",
    "    merged_df = pd.DataFrame()\n",
    "    \n",
    "    for year, url in urls.items():\n",
    "        print(f\"\\nüîÑ Fetching data for {year}...\")\n",
    "        raw_df = fetch_fee_table(session, url)\n",
    "        if raw_df.empty:\n",
    "            print(f\"‚ùå No data for {year}!\")\n",
    "            continue\n",
    "        clean_df = clean_data(raw_df, academic_year=year)\n",
    "        merged_df = pd.concat([merged_df, clean_df], ignore_index=True)\n",
    "\n",
    "    if merged_df.empty:\n",
    "        print(\"‚ùå No data collected from any year!\")\n",
    "        return\n",
    "\n",
    "    # Save CSV (optional)\n",
    "    merged_df.to_csv(\"merged_fee_collection.csv\", index=False)\n",
    "    print(\"üìÅ Saved to merged_fee_collection.csv\")\n",
    "\n",
    "    # Ensure table exists\n",
    "    engine = get_engine()\n",
    "    ensure_fees_collection_table(engine)\n",
    "    print(\"‚úÖ Fees collection table ensured.\")\n",
    "    # Push to DB\n",
    "    update_database(merged_df, TABLE_NAME)\n",
    "    print(f\"‚úÖ All done! Total records: {len(merged_df)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"><b>FEE CONCESSION REPORT</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import logging\n",
    "from datetime import date\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# ------------------ Configuration ------------------\n",
    "login_url = \"https://app.myskoolcom.tech/kotak_vizag/login\"\n",
    "data_url_2024_25 = \"https://app.myskoolcom.tech/kotak_vizag/office_fee/fee_discounts_report_receipt_wise_print?&academic_years_id=1\"\n",
    "data_url_2025_26 = \"https://app.myskoolcom.tech/kotak_vizag/office_fee/fee_discounts_report_receipt_wise_print?&academic_years_id=7\"\n",
    "\n",
    "credentials = {\n",
    "    \"uname\": \"harikiran\",\n",
    "    \"psw\": \"812551\"\n",
    "}\n",
    "\n",
    "POSTGRES_CREDENTIALS = {\n",
    "    \"username\": \"postgres\",\n",
    "    \"password\": \"Hari@123\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"kotakschooldb\",\n",
    "}\n",
    "\n",
    "TABLE_NAME = \"fee_concession_report\"\n",
    "OUTPUT_PATH = r\"D:\\GITHUB\\kotak-school-dbms\\output_data\\fee_concession_report.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Login Function ------------------\n",
    "def login_to_website():\n",
    "    session = requests.Session()\n",
    "    login_response = session.post(login_url, data=credentials)\n",
    "\n",
    "    if login_response.status_code != 200:\n",
    "        print(\"‚ùå Login request failed! Server error.\\n\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(login_response.text, \"html.parser\")\n",
    "    if soup.find(\"div\", class_=\"alert-danger\"):\n",
    "        print(\"‚ùå Login failed! Check credentials.\\n\")\n",
    "        return None\n",
    "\n",
    "    print(\"‚úÖ Login successful!\\n\")\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Fetch Table Data ------------------\n",
    "def fetch_all_concession_tables(session, data_url):\n",
    "    response = session.get(data_url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    tables = soup.find_all(\"table\", class_=\"table_view\")\n",
    "    if not tables:\n",
    "        print(\"‚ùå No fee tables found! The page structure may have changed.\")\n",
    "        return None\n",
    "\n",
    "    all_data = []\n",
    "    for table in tables:\n",
    "        df = table_to_dataframe(table)\n",
    "        if df is not None:\n",
    "            all_data.append(df)\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"‚ùå No data extracted from tables.\")\n",
    "        return None\n",
    "\n",
    "    return pd.concat(all_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ HTML Table to DataFrame ------------------\n",
    "def table_to_dataframe(table):\n",
    "    headers = [th.get_text(strip=True) for th in table.find_all(\"th\")]\n",
    "    if len(headers) > 8:\n",
    "        headers = headers[:8]\n",
    "\n",
    "    rows = []\n",
    "    for tr in table.find_all(\"tr\")[1:]:\n",
    "        cells = [td.get_text(strip=True) for td in tr.find_all(\"td\")]\n",
    "        if len(cells) >= 8:\n",
    "            rows.append(cells[:8])\n",
    "\n",
    "    return pd.DataFrame(rows, columns=headers) if rows else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Clean DataFrame ------------------\n",
    "def clean_data(df):\n",
    "    df.columns = df.columns.str.strip().str.replace(\" \", \"_\").str.lower()\n",
    "    df = df.dropna(subset=[\"student_number\"])\n",
    "    df[\"student_number\"] = df[\"student_number\"].astype(str).str.strip()\n",
    "    df[\"discount_given\"] = pd.to_numeric(df[\"discount_given\"], errors=\"coerce\").fillna(0.00)\n",
    "    df.drop(columns=['receipt_no', 'fee_name', 'fee_amount', 'total_due_amount'], errors=\"ignore\", inplace=True)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"].astype(str).str.strip(), errors=\"coerce\").dt.date\n",
    "    df = df.dropna(subset=[\"date\"])\n",
    "\n",
    "    df[\"id\"] = range(1, len(df) + 1)\n",
    "\n",
    "    # Ensure academic_year is kept if present\n",
    "    cols = ['id', 'date', 'student_number', 'student_name', 'discount_given']\n",
    "    if \"academic_year\" in df.columns:\n",
    "        cols.append(\"academic_year\")\n",
    "\n",
    "    df = df[cols]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_database(df: pd.DataFrame, table_name: str, postgres_credentials: dict):\n",
    "    password = urllib.parse.quote(postgres_credentials[\"password\"])\n",
    "    engine = create_engine(\n",
    "        f\"postgresql+psycopg2://{postgres_credentials['username']}:{password}\"\n",
    "        f\"@{postgres_credentials['host']}:{postgres_credentials['port']}/{postgres_credentials['database']}\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            print(f\"üîÑ Connecting to database {postgres_credentials['database']}...\")\n",
    "\n",
    "            # ‚úÖ Create table if not exists\n",
    "            conn.execute(text(f\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    date DATE,\n",
    "                    student_number VARCHAR(20),\n",
    "                    student_name TEXT,\n",
    "                    discount_given NUMERIC(10, 2),\n",
    "                    academic_year VARCHAR(10)\n",
    "                );\n",
    "            \"\"\"))\n",
    "            print(f\"‚úÖ Ensured '{table_name}' table exists.\")\n",
    "\n",
    "            # üîÑ Clear existing records\n",
    "            print(f\"‚ö†Ô∏è Deleting existing records from: {table_name}\")\n",
    "            conn.execute(text(f\"DELETE FROM {table_name};\"))\n",
    "            print(f\"‚úÖ Table '{table_name}' cleared.\\n\")\n",
    "\n",
    "        # üì• Insert Data\n",
    "        print(f\"üì• Inserting data into {table_name} table...\")\n",
    "        df.to_sql(name=table_name, con=engine, if_exists=\"append\", index=False, method=\"multi\", chunksize=1000)\n",
    "        print(f\"‚úÖ Data successfully inserted into '{table_name}' table.\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"‚ùå Error updating database: {e}\", exc_info=True)\n",
    "        print(f\"‚ùå Error occurred while updating database: {e}\")\n",
    "\n",
    "    finally:\n",
    "        engine.dispose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    session = login_to_website()\n",
    "    if session is None:\n",
    "        return\n",
    "\n",
    "    df_2024_25 = fetch_all_concession_tables(session, data_url_2024_25)\n",
    "    df_2025_26 = fetch_all_concession_tables(session, data_url_2025_26)\n",
    "\n",
    "    if df_2024_25 is None or df_2025_26 is None:\n",
    "        print(\"‚ùå Could not fetch data for one or both academic years.\")\n",
    "        return\n",
    "\n",
    "    df_2024_25[\"academic_year\"] = \"2024-25\"\n",
    "    df_2025_26[\"academic_year\"] = \"2025-26\"\n",
    "\n",
    "    merged_df = pd.concat([df_2024_25, df_2025_26], ignore_index=True)\n",
    "\n",
    "    print(\"‚úÖ Data extracted successfully! Cleaning data...\\n\")\n",
    "    cleaned_df = clean_data(merged_df)\n",
    "\n",
    "    output_file = r\"D:\\\\GITHUB\\\\kotak-school-dbms\\\\output_data\\\\fee_concession_report_combined.csv\"\n",
    "    cleaned_df.to_csv(output_file, index=False)\n",
    "    print(cleaned_df.columns)\n",
    "    print(f\"‚úÖ Data saved to '{output_file}'\\n\")\n",
    "\n",
    "    update_database(cleaned_df, TABLE_NAME, POSTGRES_CREDENTIALS)\n",
    "    print(f\"‚úÖ {len(cleaned_df)} records entered into the database\")\n",
    "\n",
    "    print(cleaned_df.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Login successful!\n",
      "\n",
      "‚úÖ Data extracted successfully! Cleaning data...\n",
      "\n",
      "Index(['id', 'date', 'student_number', 'student_name', 'discount_given',\n",
      "       'academic_year'],\n",
      "      dtype='object')\n",
      "‚úÖ Data saved to 'D:\\\\GITHUB\\\\kotak-school-dbms\\\\output_data\\\\fee_concession_report_combined.csv'\n",
      "\n",
      "üîÑ Connecting to database kotakschooldb...\n",
      "‚úÖ Ensured 'fee_concession_report' table exists.\n",
      "‚ö†Ô∏è Deleting existing records from: fee_concession_report\n",
      "‚úÖ Table 'fee_concession_report' cleared.\n",
      "\n",
      "üì• Inserting data into fee_concession_report table...\n",
      "‚úÖ Data successfully inserted into 'fee_concession_report' table.\n",
      "\n",
      "‚úÖ 200 records entered into the database\n",
      "      id        date student_number                                       student_name  discount_given academic_year\n",
      "0      1  2024-07-27          15660                        POTHIRENDI YAASHVAN (V - A)           500.0       2024-25\n",
      "1      2  2024-07-27          16070                     DONGA YASMITH JAYA SAI (V - B)           500.0       2024-25\n",
      "2      3  2024-07-27          16105                           JAGARANA GEETIKA (V - A)           500.0       2024-25\n",
      "3      4  2024-07-27          16165                            SUMUEL NAGARAPU (X - B)           500.0       2024-25\n",
      "4      5  2024-07-27          15018                              GADHAM ESTHER (X - A)           500.0       2024-25\n",
      "5      6  2024-07-27          15363                          MADAGALA GEETHIKA (X - A)           500.0       2024-25\n",
      "6      7  2024-07-27          16921                             AKULA SAANVI (UKG - A)           500.0       2024-25\n",
      "7      8  2024-07-27          16970                            SATHWIK DUMMU (UKG - A)           500.0       2024-25\n",
      "8      9  2024-07-27          16985                TEKKALI MONISH SIVA KUMAR (UKG - C)           500.0       2024-25\n",
      "9     10  2024-07-27          16779                 RAVURI SANJAY SAMRAT KUMAR (I - C)           500.0       2024-25\n",
      "10    11  2024-07-27          16967                             TADITURI JATIN (I - B)           500.0       2024-25\n",
      "11    12  2024-07-27          15213         RAGHUPATRUNI PRAERAN HARISH KUMAR (VI - B)           500.0       2024-25\n",
      "12    13  2024-07-27          15532                    THUPAKULA SURYA CHARAN (VI - A)           500.0       2024-25\n",
      "13    14  2024-07-27          15526                          NISTALA AARADHYA (VI - D)           500.0       2024-25\n",
      "14    15  2024-07-27          16765                          KADIYALA REVANTH (VI - C)           500.0       2024-25\n",
      "15    16  2024-07-27          15261                        NISTALA CHARISHMA (VII - B)           500.0       2024-25\n",
      "16    17  2024-07-27          16499              AMRUTHA SESHAKUMARI CHAVALI (VII - B)           500.0       2024-25\n",
      "17    18  2024-07-27          16416                         ANANYA VASUPALLI (VII - D)           500.0       2024-25\n",
      "18    19  2024-07-27          15278                           UPPADA JOSEPH (VIII - B)           500.0       2024-25\n",
      "19    20  2024-07-27          17014                 KIRLAMPALLI JAI KRISHNA (VIII - A)           500.0       2024-25\n",
      "20    21  2024-07-27          14497                        SARIPILLI DEERAJ (VIII - B)           500.0       2024-25\n",
      "21    22  2024-07-27          14861             THUPAKULA CHARANYA PRANITHA (VIII - B)           500.0       2024-25\n",
      "22    23  2024-07-27          15019                           GADHAM HANNAH (VIII - C)           500.0       2024-25\n",
      "23    24  2024-07-27          15277                             UPPADA ANJALI (IX - C)           500.0       2024-25\n",
      "24    25  2024-07-27          14502                          NEELAPU SUDIKSHA (IX - C)           500.0       2024-25\n",
      "25    26  2024-07-27          16132                PRANITHA PALURI (X (2024-2025) - A)           500.0       2024-25\n",
      "26    27  2024-07-27          15275                  ADITYA PALEPU (X (2024-2025) - B)           500.0       2024-25\n",
      "27    28  2024-07-27          14606       GAGAN VATSAV CHELLUBOINA (X (2024-2025) - C)           500.0       2024-25\n",
      "28    29  2024-07-27          15402                KUSUMA KURMANNA (X (2024-2025) - C)           500.0       2024-25\n",
      "29    30  2024-07-29          16587                          MOOGI JAYVARDHAN (IV - A)           500.0       2024-25\n",
      "30    31  2024-07-29          16393                     TEKKALI VEDASYA GOWRI (II - B)           400.0       2024-25\n",
      "31    32  2024-07-29          16393                     TEKKALI VEDASYA GOWRI (II - B)           500.0       2024-25\n",
      "32    33  2024-07-29          16340                          NIMMALA JAAHNAVI (II - C)           500.0       2024-25\n",
      "33    34  2024-07-29          17091                TIRUMAREDDY KRISHNA KUMAR (III - A)           500.0       2024-25\n",
      "34    35  2024-07-29          16441                   SONALI SINGH KSHATRIYA (III - C)           500.0       2024-25\n",
      "35    36  2024-07-29          16500             TIRUMALA SAI SARANYA CHAVALI (III - A)           500.0       2024-25\n",
      "36    37  2024-07-29          17060                           VANAM SHAAMISH (III - D)           500.0       2024-25\n",
      "37    38  2024-07-29          15711                        SANCHITA MAHAPATRA (IV - A)           500.0       2024-25\n",
      "38    39  2024-07-30          16192                        MADAGALA MADHULIKA (VI - A)           500.0       2024-25\n",
      "39    40  2024-07-31          16324                        CHINMAYI CHANDRANA (II - A)           500.0       2024-25\n",
      "40    41  2024-08-01          15748                 VAIBHAV SHARMA (X (2024-2025) - B)           500.0       2024-25\n",
      "41    42  2024-08-02          14606       GAGAN VATSAV CHELLUBOINA (X (2024-2025) - C)         20900.0       2024-25\n",
      "42    43  2024-08-13          14881                            SHAIK ANEESA (VIII - A)           500.0       2024-25\n",
      "43    44  2024-08-19          15347                           DHANALA RACHANA (VI - B)         15400.0       2024-25\n",
      "44    45  2024-08-19          14615                            DHANALA ASHIKA (IX - A)         19800.0       2024-25\n",
      "45    46  2024-09-14          16228            DAKSHETH EVAN ADARI (X (2024-2025) - C)         20900.0       2024-25\n",
      "46    47  2024-09-28          14321                      KARRI RANVITHA RAGHNI (X - B)         20900.0       2024-25\n",
      "47    48  2024-10-18          15744                        MOHAMMED ABDUL AAIZ (V - B)         14850.0       2024-25\n",
      "48    49  2024-10-29          14747                            AKULA SAMANTHA (IX - A)         19800.0       2024-25\n",
      "49    50  2024-12-23          15402                KUSUMA KURMANNA (X (2024-2025) - C)         20400.0       2024-25\n",
      "50    51  2024-12-24          15402                KUSUMA KURMANNA (X (2024-2025) - C)           500.0       2024-25\n",
      "51    52  2025-02-04          16183         MOHAMMAD ALIYA REHAMAN (X (2024-2025) - B)         20900.0       2024-25\n",
      "52    53  2025-02-04          13917    VENKATA NAGA AASHINI KORADA (X (2024-2025) - B)         20900.0       2024-25\n",
      "53    54  2025-02-04          14406              GANDEPALLI LEISHA SRI AAPYAYA (X - A)         20900.0       2024-25\n",
      "54    55  2025-02-09          17069                         GUNTURU VIDYA SRI (VI - D)          7700.0       2024-25\n",
      "55    56  2025-02-09          17070                        GUNTURU DIVYASRI (VIII - A)          7975.0       2024-25\n",
      "56    57  2025-02-09          16405                              AVNIKA PAUL (III - A)         14300.0       2024-25\n",
      "57    58  2025-02-09          15274              CHINTAPALLI PAVAN KARTHIKEYA (IX - B)          2500.0       2024-25\n",
      "58    59  2025-02-09          15546                 CHINTHAPALLI THANVI LASYA (VI - D)          2500.0       2024-25\n",
      "59    60  2025-02-09          16184                          DALLI HETHANSHRI (IV - C)          7425.0       2024-25\n",
      "60    61  2025-02-19          16600     RAVI KUMAR RANVITHA PRAYSHITHA SONGA (III - D)         14300.0       2024-25\n",
      "61    62  2025-02-19          15980                          DANDA NITYA SREE (IV - D)          7425.0       2024-25\n",
      "62    63  2025-02-19          16975                      MISHIKA POLAMARASETTI (V - D)         14850.0       2024-25\n",
      "63    64  2025-02-20          15602                 PYLA PYLA CHETHAN SREEKAR (VI - B)          7700.0       2024-25\n",
      "64    65  2025-02-20          16564                    POLAMARASETTY TEJASWI (VII - D)          7700.0       2024-25\n",
      "65    66  2025-02-20          14932                     PYLA HANVITH CHARAN (VIII - A)          7975.0       2024-25\n",
      "66    67  2025-02-20          15325                         CHALLA MOKSHITHA (VII - B)          5000.0       2024-25\n",
      "67    68  2025-02-21          16163                     KONADA NAVYA KEERTHANA (V - B)          2500.0       2024-25\n",
      "68    69  2025-02-21          15526                          NISTALA AARADHYA (VI - D)          7700.0       2024-25\n",
      "69    70  2025-02-21          15612                         VIYYAPU SIDESWARI (VI - A)          4000.0       2024-25\n",
      "70    71  2025-02-21          15261                        NISTALA CHARISHMA (VII - B)          7700.0       2024-25\n",
      "71    72  2025-02-21          14254                    SARIPILLI SIRI CHANDANA (X - B)          4000.0       2024-25\n",
      "72    73  2025-03-03          14850                       MADDILA KIRANMAYI (VIII - D)          3000.0       2024-25\n",
      "73    74  2025-03-04          14606       GAGAN VATSAV CHELLUBOINA (X (2024-2025) - C)           500.0       2024-25\n",
      "74    75  2025-03-08          14000                SHASANK GUVVADA (X (2024-2025) - A)         10450.0       2024-25\n",
      "75    76  2025-03-08          14931                      KANDIPILLI SHASANK (VIII - D)          2500.0       2024-25\n",
      "76    77  2025-03-08          15775                        KANDIPILLI JASMITHA (V - D)          2500.0       2024-25\n",
      "77    78  2025-03-08          16917                      DOPPA RUSHANTH BABU (UKG - C)          6050.0       2024-25\n",
      "78    79  2025-03-08          16347                       DOPPA SASHANTH BABU (II - D)          7150.0       2024-25\n",
      "79    80  2025-03-08          14868                    AKULA HOLY EVANGILEN (VIII - D)          3000.0       2024-25\n",
      "80    81  2025-03-08          15869                         ALOYSIUS VERSILA (VII - C)          7700.0       2024-25\n",
      "81    82  2025-03-08          15939               ALPHONSA VERSILA (X (2024-2025) - A)         10450.0       2024-25\n",
      "82    83  2025-03-08          17020                       JINNALA SIDDHARDHA (III - B)          7150.0       2024-25\n",
      "83    84  2025-03-08          13845     THANOJ KRISHNA SAI JONNADA (X (2024-2025) - B)          6000.0       2024-25\n",
      "84    85  2025-03-08          14228                        YALLAMALLI JAYASREE (X - C)          8000.0       2024-25\n",
      "85    86  2025-03-08          16374                          MOYYA PAARDHAVI (III - C)          5000.0       2024-25\n",
      "86    87  2025-03-08          15648                         MOYYA PREM SATWIK (VI - B)          5000.0       2024-25\n",
      "87    88  2025-03-08          14108                               AKULA BLESSY (X - C)          3000.0       2024-25\n",
      "88    89  2025-03-19          16143                 VELANGINI YASHMITHA KOYYA (IV - B)          7425.0       2024-25\n",
      "89    90  2025-03-19          15788                        ADDIPILLI DEEKSHITH (V - A)          5000.0       2024-25\n",
      "90    91  2025-03-19          15511                         BOOTHU NAYANA SRI (VI - B)          7700.0       2024-25\n",
      "91    92  2025-03-19          16200                       BOOTHU SUREKHA SRI (III - D)          7150.0       2024-25\n",
      "92    93  2025-03-19          16024                    KOYYA YOGITASREE YADAV (IV - D)          3000.0       2024-25\n",
      "93    94  2025-03-19          15231                   KOYYA GANESH CHAITANYA (VII - B)          3000.0       2024-25\n",
      "94    95  2025-03-19          16637                       LAXMANA VASU DEETHYA (I - A)          6050.0       2024-25\n",
      "95    96  2025-03-19          15945                   POTNURU LEKSHITA LAASYA (VI - A)             0.0       2024-25\n",
      "96    97  2025-03-19          15945                   POTNURU LEKSHITA LAASYA (VI - A)         15400.0       2024-25\n",
      "97    98  2025-03-19          14224                        GUNANA MAHENDRA SAI (X - A)         10450.0       2024-25\n",
      "98    99  2025-03-19          16026                      DEEKSHITHA SRI KOYYA (IV - B)          3000.0       2024-25\n",
      "99   100  2025-03-19          15880                          BOBBADI MANJEET (VII - D)          7700.0       2024-25\n",
      "100  101  2025-03-20          15479                       CHEEDI ASHLIN MOSES (VI - B)         15400.0       2024-25\n",
      "101  102  2025-03-20          16984                     CHEEDI CHARLIN MOSES (UKG - C)         12100.0       2024-25\n",
      "102  103  2025-03-21          15780                           KODI GAGANA SREE (V - B)          3000.0       2024-25\n",
      "103  104  2025-03-22          17052                           FRANK NIHAARIKA (II - C)          7150.0       2024-25\n",
      "104  105  2025-03-22          15923                           MORSA TRISWANTH (IV - C)          7425.0       2024-25\n",
      "105  106  2025-03-22          15301                         MORSA NAVAKANTH (VIII - C)          7975.0       2024-25\n",
      "106  107  2025-04-05          13834                    FAZILA KHAN (X (2024-2025) - B)         20900.0       2024-25\n",
      "107  108  2025-04-05          17126                      PONNADA BHAGATSINGH (UKG - B)          6050.0       2024-25\n",
      "108  109  2025-04-05          17125                      PONNADA GOWRILANKESH (II - C)          7150.0       2024-25\n",
      "109  110  2025-04-05          15158          TELU V S SURYA SATYA SAI JATIN (VIII - B)          7975.0       2024-25\n",
      "110  111  2025-04-05          16783                   VURIMITI GOPIKA SNIGDHA (IV - C)          4000.0       2024-25\n",
      "111  112  2025-04-05          16782                    VURIMITI ROSHITA SREE (VII - D)          4000.0       2024-25\n",
      "112  113  2025-04-05          14488                               RIANNA SIMON (X - A)         10450.0       2024-25\n",
      "113  114  2025-04-05          15746                       NAKKA YASHA YASHMINA (V - D)          7425.0       2024-25\n",
      "114  115  2025-04-05          15746                       NAKKA YASHA YASHMINA (V - D)          7425.0       2024-25\n",
      "115  116  2025-04-05          15625                     SEERA JAHNAVI SREE SAI (V - D)          7425.0       2024-25\n",
      "116  117  2025-04-05          16969                            SEERA AKILESH (UKG - A)          6050.0       2024-25\n",
      "117  118  2025-04-05          14099            RHEON MARIO REBEIRO (X (2024-2025) - A)         10450.0       2024-25\n",
      "118  119  2025-04-05          15631                             SHAIK HANEEFA (VI - C)          7700.0       2024-25\n",
      "119  120  2025-04-05          16317                            SHAIK HANEESHA (IV - A)          7425.0       2024-25\n",
      "120  121  2025-04-30          16654              MARTIN ANTHONY ROHITH PRAKASH (I - A)          6050.0       2024-25\n",
      "121  122  2025-04-30          14517                   MARTIN VELANGINI NITHYA (IX - A)          9900.0       2024-25\n",
      "122  123  2025-04-30          14867                      PIDUGU ROHAN BABJI (VIII - C)         15950.0       2024-25\n",
      "123  124  2025-04-30          14907               GUNTUBOINA SHANMUKHA TEJA (VIII - D)         15950.0       2024-25\n",
      "124  125  2025-04-30          15370                         KOYYA SOWMYA SRI (VII - C)          4000.0       2024-25\n",
      "125  126  2025-04-30          15554                             ARJA NAYNEKKA (VI - D)          5000.0       2024-25\n",
      "126  127  2025-04-30          15185                       VADDADI SAI CHARAN (VII - B)          4000.0       2024-25\n",
      "127  128  2025-04-30          17050                           TEDDU PRADHANYA (II - B)          4000.0       2024-25\n",
      "128  129  2025-04-30          16179                      INDUBILLI DHIKSHITH (III - D)          5000.0       2024-25\n",
      "129  130  2025-04-30          15400                   CHINAWADA MANOJ YADAV (VIII - C)          7975.0       2024-25\n",
      "130  131  2025-04-30          16263                     GANDRETI SOHAN SHOURYA (V - A)          7425.0       2024-25\n",
      "131  132  2025-04-30          16762                         TAMMANA MANASWINI (II - D)         14300.0       2024-25\n",
      "132  133  2025-04-30          15621                            MUDDA KEERTHANA (X - B)         20900.0       2024-25\n",
      "133  134  2025-04-30          14546                            KONDALA JOSHNA (IX - C)          9900.0       2024-25\n",
      "134  135  2025-04-30          14669                           PENTA SATHVIK (VIII - B)          7975.0       2024-25\n",
      "135  136  2025-04-30          14958                           MATHA MANJULA (VIII - D)          7975.0       2024-25\n",
      "136  137  2025-04-30          14543               KASARAPU TEJASWANI NIKHITHA (IX - A)          4000.0       2024-25\n",
      "137  138  2025-04-30          16193                          KOPPULA YASWANTH (IV - C)          7425.0       2024-25\n",
      "138  139  2025-04-30          14630                OMMI PAVANI PRIYA VARSHINI (IX - C)         19800.0       2024-25\n",
      "139  140  2025-04-30          14243                                MUKESH OMMI (X - A)         20900.0       2024-25\n",
      "140  141  2025-04-30          15669                             KORNU ROHAN (VIII - D)          5000.0       2024-25\n",
      "141  142  2025-04-30          16076            PATNALA SAI MAHIMA PRAJWALITA (VII - B)          4000.0       2024-25\n",
      "142  143  2025-04-30          16414                     DUNGA CATHERINE FAITH (II - C)          3000.0       2024-25\n",
      "143  144  2025-04-30          15850                        DUNGA RABBI JOSEPH (IV - C)          3000.0       2024-25\n",
      "144  145  2025-04-30          15613                          DUNGA NITYA PAUL (VI - D)          3000.0       2024-25\n",
      "145  146  2025-04-30          14944                   KADIRI SRAVAN BHARGAV (VIII - C)          5000.0       2024-25\n",
      "146  147  2025-04-30          14863  KANCHARLA VENKATA BHARATA PADMA KUMARI (VIII - D)          3500.0       2024-25\n",
      "147  148  2025-04-30          13863                 UPENDRA MUTCHI (X (2024-2025) - C)          4000.0       2024-25\n",
      "148  149  2025-04-30          15520                    KANCHARLA SAI BHARGAVI (VI - B)          3000.0       2024-25\n",
      "149  150  2025-04-30          15584                              SOHAN REGINA (VI - C)          3000.0       2024-25\n",
      "150  151  2025-04-30          14953                           REGINA JATHIN (VIII - C)          3000.0       2024-25\n",
      "151  152  2025-04-30          16077                     MIRIYALA JOSEPH SUJIT (IX - B)          9900.0       2024-25\n",
      "152  153  2025-04-30          16078        JASIEL MAHARAJ MIRIYALA (X (2024-2025) - B)         10450.0       2024-25\n",
      "153  154  2025-05-03          14879                         BAVIRI THANUSKA (VIII - C)         15950.0       2024-25\n",
      "154  155  2025-05-03          15459                            BAVIRI GOWTHAM (VI - D)          7700.0       2024-25\n",
      "155  156  2025-05-03          15459                            BAVIRI GOWTHAM (VI - D)          7700.0       2024-25\n",
      "156  157  2025-07-04          16967                             TADITURI JATIN (I - B)           500.0       2025-26\n",
      "157  158  2025-07-04          17221               YERRAMSETTY CHINMAYI CHAITRA (I - C)           500.0       2025-26\n",
      "158  159  2025-07-04          17274             DONGA SHANKARA NAGA SAI PRANAY (I - C)           500.0       2025-26\n",
      "159  160  2025-07-04          16393                     TEKKALI VEDASYA GOWRI (II - B)           500.0       2025-26\n",
      "160  161  2025-07-04          17012                  CHENNA HANEESH VIRENDHRA (II - B)           500.0       2025-26\n",
      "161  162  2025-07-04          16340                          NIMMALA JAAHNAVI (II - C)           500.0       2025-26\n",
      "162  163  2025-07-04          17023                      MOHAMMAD SHADMAN ALI (II - C)           500.0       2025-26\n",
      "163  164  2025-07-04          17084                PREM SWAROOP LANKALAPALLI (III - D)           500.0       2025-26\n",
      "164  165  2025-07-04          16317                            SHAIK HANEESHA (IV - A)           500.0       2025-26\n",
      "165  166  2025-07-04          16813                         CHERUKURU MANVITH (IV - C)           500.0       2025-26\n",
      "166  167  2025-07-04          16105                           JAGARANA GEETIKA (V - A)           500.0       2025-26\n",
      "167  168  2025-07-04          16105                           JAGARANA GEETIKA (V - A)           500.0       2025-26\n",
      "168  169  2025-07-04          17025                             SIDDIQUA FATMA (V - A)           500.0       2025-26\n",
      "169  170  2025-07-04          16070                     DONGA YASMITH JAYA SAI (V - B)           500.0       2025-26\n",
      "170  171  2025-07-04          15744                        MOHAMMED ABDUL AAIZ (V - B)           500.0       2025-26\n",
      "171  172  2025-07-04          17034                       LAVETI REVANTH ANISH (V - D)           500.0       2025-26\n",
      "172  173  2025-07-04          16192                        MADAGALA MADHULIKA (VI - A)           500.0       2025-26\n",
      "173  174  2025-07-04          15213         RAGHUPATRUNI PRAERAN HARISH KUMAR (VI - B)           500.0       2025-26\n",
      "174  175  2025-07-04          15396                          SARIPILLI ANUHYA (VI - D)           500.0       2025-26\n",
      "175  176  2025-07-04          14497                        SARIPILLI DEERAJ (VIII - B)           500.0       2025-26\n",
      "176  177  2025-07-04          15019                           GADHAM HANNAH (VIII - C)           500.0       2025-26\n",
      "177  178  2025-07-04          16068                 KOPPALA CHAITRA CHARISHMA (IX - A)           500.0       2025-26\n",
      "178  179  2025-07-04          14502                          NEELAPU SUDIKSHA (IX - C)           500.0       2025-26\n",
      "179  180  2025-07-04          15018                              GADHAM ESTHER (X - A)           500.0       2025-26\n",
      "180  181  2025-07-04          15363                          MADAGALA GEETHIKA (X - A)           500.0       2025-26\n",
      "181  182  2025-07-04          14488                               RIANNA SIMON (X - A)           500.0       2025-26\n",
      "182  183  2025-07-04         14384A                        ADARI NIRMAL NITISH (X - B)           500.0       2025-26\n",
      "183  184  2025-07-04          16921                             AKULA SAANVI (UKG - A)           500.0       2025-26\n",
      "184  185  2025-07-04          17048                      UDDANDAPU NIRVIGHNA (UKG - A)           500.0       2025-26\n",
      "185  186  2025-07-04          17322                       VARADHI DEEKSHITHA (UKG - B)           500.0       2025-26\n",
      "186  187  2025-07-04          16985                TEKKALI MONISH SIVA KUMAR (UKG - C)           500.0       2025-26\n",
      "187  188  2025-07-08          16587                          MOOGI JAYVARDHAN (IV - A)           500.0       2025-26\n",
      "188  189  2025-07-08          16325                           IAN PRASAD MALE (II - C)           500.0       2025-26\n",
      "189  190  2025-07-08          15324                         SOURAV MAHAPATRA (VII - B)           500.0       2025-26\n",
      "190  191  2025-07-08          15048         VANAPALLI VENKATA SAI KARTHIKEYA (VII - C)           500.0       2025-26\n",
      "191  192  2025-07-15          15831                         MYLAPILLI SHASANK (VI - B)           500.0       2025-26\n",
      "192  193  2025-07-15          15832                   MYLAPILLI JEEVAN KUMAR (VII - C)           500.0       2025-26\n",
      "193  194  2025-07-15          14321                      KARRI RANVITHA RAGHNI (X - B)           500.0       2025-26\n",
      "194  195  2025-07-18          15660                        POTHIRENDI YAASHVAN (V - A)           500.0       2025-26\n",
      "195  196  2025-07-18          16500             TIRUMALA SAI SARANYA CHAVALI (III - A)           500.0       2025-26\n",
      "196  197  2025-07-18          17060                           VANAM SHAAMISH (III - D)           500.0       2025-26\n",
      "197  198  2025-07-18          16499              AMRUTHA SESHAKUMARI CHAVALI (VII - B)           500.0       2025-26\n",
      "198  199  2025-07-21          16765                          KADIYALA REVANTH (VI - C)           500.0       2025-26\n",
      "199  200  2025-07-21          14867                      PIDUGU ROHAN BABJI (VIII - C)           500.0       2025-26\n"
     ]
    }
   ],
   "source": [
    "# ------------------ Run Script ------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
